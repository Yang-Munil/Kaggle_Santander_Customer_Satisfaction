{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, StratifiedKFold, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "\n",
    "\n",
    "# 일반적으로 회귀에는 기본 k-겹 교차검증을 사용하고, 분류에는 StratifiedKFold를 사용한다.\n",
    "\n",
    "# 또한, cross_val_score 함수에는 KFold의 매개변수를 제어할 수가 없으므로, \n",
    "\n",
    "# 따로 KFold 객체를 만들고 매개변수를 조정한 다음에 cross_val_score의 cv 매개변수에 넣어야 한다.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings         # warnings : 버전 충돌 및 특정 예외 처리를 위해 불러온 내장 모듈\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "3                      0.0                      0.0  ...   \n",
       "4                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./train.csv\",encoding='latin-1')\n",
    "print('dataset shape:', train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    73012\n",
      "1     3008\n",
      "Name: TARGET, dtype: int64\n",
      "unsatisfied 비율은 0.04\n"
     ]
    }
   ],
   "source": [
    "# 극 불균형 상태임을 확인\n",
    "\n",
    "print(train['TARGET'].value_counts())\n",
    "\n",
    "unsatisfied_cnt = train[train['TARGET'] == 1]['TARGET'].count()\n",
    "total_cnt = train['TARGET'].count()\n",
    "\n",
    "print('unsatisfied 비율은 {0:.2f}'.format((unsatisfied_cnt / total_cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모두 수치형 변수\n",
    "\n",
    "train.describe( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2         74165\n",
      " 8           138\n",
      "-999999      116\n",
      " 9           110\n",
      " 3           108\n",
      " 1           105\n",
      " 13           98\n",
      " 7            97\n",
      " 4            86\n",
      " 12           85\n",
      "Name: var3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['var3'].value_counts( )[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var3 피처 값 대체 및 ID 피처 드롭\n",
    "train['var3'].replace(-999999, 2, inplace=True)\n",
    "train.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train['TARGET']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 369)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(['TARGET'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 Shape:(60816, 369), 테스트 세트 Shape:(15204, 369)\n",
      " 학습 세트 레이블 값 분포 비율\n",
      "0    0.960964\n",
      "1    0.039036\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      " 테스트 세트 레이블 값 분포 비율\n",
      "0    0.9583\n",
      "1    0.0417\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape , X_test.shape))\n",
    "\n",
    "print(' 학습 세트 레이블 값 분포 비율')\n",
    "print(y_train.value_counts()/train_cnt)\n",
    "print('\\n 테스트 세트 레이블 값 분포 비율')\n",
    "print(y_test.value_counts()/test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 언더 샘플링¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM 모델 학습과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Under Sampling\n",
    "\n",
    "- 다수클래스 데이터 중에서 무작위로 선별하여 제거."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, stratify = y)\n",
    "\n",
    "# 분류학습시 stratify = target으로 설정해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = RandomUnderSampler().fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 Shape:(4812, 369), 테스트 세트 Shape:(15204, 369)\n",
      " 학습 세트 레이블 값 분포 비율\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      " 테스트 세트 레이블 값 분포 비율\n",
      "0    0.960405\n",
      "1    0.039595\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 추후 오버,언더,하이드리브 샘플링 적용시 레이블 값 분포를 보기위한 코드.\n",
    "\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape , X_test.shape))\n",
    "\n",
    "print(' 학습 세트 레이블 값 분포 비율')\n",
    "print(y_train.value_counts()/train_cnt)\n",
    "print('\\n 테스트 세트 레이블 값 분포 비율')\n",
    "print(y_test.value_counts()/test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaysianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_params = {\n",
    "    'num_leaves': (24, 45),\n",
    "    'colsample_bytree':(0.5, 1), \n",
    "    'subsample': (0.5, 1),\n",
    "    'max_depth': (4, 12),\n",
    "    'reg_alpha': (0, 0.5),\n",
    "    'reg_lambda': (0, 0.5), \n",
    "    'min_split_gain': (0.001, 0.1),\n",
    "    'min_child_weight':(5, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def lgb_roc_eval(num_leaves, colsample_bytree, subsample, max_depth, reg_alpha, reg_lambda, min_split_gain, min_child_weight):\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimator\":200,\n",
    "        \"learning_rate\":0.02,\n",
    "        'num_leaves': int(round(num_leaves)),\n",
    "        'colsample_bytree': colsample_bytree, \n",
    "        'subsample': subsample,\n",
    "        'max_depth': int(round(max_depth)),\n",
    "        'reg_alpha': reg_alpha,\n",
    "        'reg_lambda': reg_lambda, \n",
    "        'min_split_gain': min_split_gain,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    print(\"params:\", params)\n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=30, eval_metric=\"auc\", verbose=100 )\n",
    "    best_iter = lgb_model.best_iteration_\n",
    "    print('best_iter:', best_iter)\n",
    "    valid_proba = lgb_model.predict_proba(X_test, num_iteration=best_iter)[:, 1]\n",
    "    roc_preds = roc_auc_score(y_test, valid_proba)\n",
    "    print('roc_auc:', roc_preds)\n",
    "    return roc_preds\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "BO_lgb = BayesianOptimization(lgb_roc_eval, bayes_params, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | max_depth | min_ch... | min_sp... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 33, 'colsample_bytree': 0.7744067519636624, 'subsample': 0.9458865003910399, 'max_depth': 10, 'reg_alpha': 0.32294705653332806, 'reg_lambda': 0.21879360563134626, 'min_split_gain': 0.05494343511669279, 'min_child_weight': 32.12435192322397, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.840734\tvalid_0's binary_logloss: 0.517491\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's auc: 0.840766\tvalid_0's binary_logloss: 0.517737\n",
      "best_iter: 99\n",
      "roc_auc: 0.8407661354358684\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8408  \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 9.722   \u001b[0m | \u001b[0m 32.12   \u001b[0m | \u001b[0m 0.05494 \u001b[0m | \u001b[0m 32.9    \u001b[0m | \u001b[0m 0.3229  \u001b[0m | \u001b[0m 0.2188  \u001b[0m | \u001b[0m 0.9459  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 36, 'colsample_bytree': 0.9818313802505146, 'subsample': 0.5435646498507704, 'max_depth': 7, 'reg_alpha': 0.4627983191463305, 'reg_lambda': 0.03551802909894347, 'min_split_gain': 0.05336059705553755, 'min_child_weight': 40.627626713719906, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.839239\tvalid_0's binary_logloss: 0.517307\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.839239\tvalid_0's binary_logloss: 0.517307\n",
      "best_iter: 100\n",
      "roc_auc: 0.8392391293961006\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8392  \u001b[0m | \u001b[0m 0.9818  \u001b[0m | \u001b[0m 7.068   \u001b[0m | \u001b[0m 40.63   \u001b[0m | \u001b[0m 0.05336 \u001b[0m | \u001b[0m 35.93   \u001b[0m | \u001b[0m 0.4628  \u001b[0m | \u001b[0m 0.03552 \u001b[0m | \u001b[0m 0.5436  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 45, 'colsample_bytree': 0.5101091987201629, 'subsample': 0.8902645881432277, 'max_depth': 11, 'reg_alpha': 0.3995792821083618, 'reg_lambda': 0.23073968112646592, 'min_split_gain': 0.08713120267643511, 'min_child_weight': 40.01705379274327, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.839346\tvalid_0's binary_logloss: 0.525599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.839346\tvalid_0's binary_logloss: 0.525599\n",
      "best_iter: 100\n",
      "roc_auc: 0.8393460641854458\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8393  \u001b[0m | \u001b[0m 0.5101  \u001b[0m | \u001b[0m 10.66   \u001b[0m | \u001b[0m 40.02   \u001b[0m | \u001b[0m 0.08713 \u001b[0m | \u001b[0m 44.55   \u001b[0m | \u001b[0m 0.3996  \u001b[0m | \u001b[0m 0.2307  \u001b[0m | \u001b[0m 0.8903  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 35, 'colsample_bytree': 0.5591372129344666, 'subsample': 0.8871168447171083, 'max_depth': 9, 'reg_alpha': 0.2073309699952618, 'reg_lambda': 0.13227780605231348, 'min_split_gain': 0.09452222278790881, 'min_child_weight': 11.450897933407088, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.840143\tvalid_0's binary_logloss: 0.519499\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's auc: 0.840282\tvalid_0's binary_logloss: 0.519933\n",
      "best_iter: 98\n",
      "roc_auc: 0.8402823692744953\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8403  \u001b[0m | \u001b[0m 0.5591  \u001b[0m | \u001b[0m 9.119   \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 0.09452 \u001b[0m | \u001b[0m 34.96   \u001b[0m | \u001b[0m 0.2073  \u001b[0m | \u001b[0m 0.1323  \u001b[0m | \u001b[0m 0.8871  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 37, 'colsample_bytree': 0.7280751661082743, 'subsample': 0.8409101495517417, 'max_depth': 9, 'reg_alpha': 0.30846699843737846, 'reg_lambda': 0.4718740392573121, 'min_split_gain': 0.062145914210511834, 'min_child_weight': 5.845541019635982, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.841566\tvalid_0's binary_logloss: 0.514193\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's auc: 0.84188\tvalid_0's binary_logloss: 0.514681\n",
      "best_iter: 98\n",
      "roc_auc: 0.8418796792502369\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.8419  \u001b[0m | \u001b[95m 0.7281  \u001b[0m | \u001b[95m 8.547   \u001b[0m | \u001b[95m 5.846   \u001b[0m | \u001b[95m 0.06215 \u001b[0m | \u001b[95m 36.85   \u001b[0m | \u001b[95m 0.3085  \u001b[0m | \u001b[95m 0.4719  \u001b[0m | \u001b[95m 0.8409  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 40, 'colsample_bytree': 0.8071874312473927, 'subsample': 0.6669384227592721, 'max_depth': 11, 'reg_alpha': 0.3518457494436385, 'reg_lambda': 0.0582019311377151, 'min_split_gain': 0.07495751902247628, 'min_child_weight': 36.927528592278506, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.840707\tvalid_0's binary_logloss: 0.517469\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's auc: 0.840744\tvalid_0's binary_logloss: 0.51793\n",
      "best_iter: 98\n",
      "roc_auc: 0.8407436108738575\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8407  \u001b[0m | \u001b[0m 0.8072  \u001b[0m | \u001b[0m 10.54   \u001b[0m | \u001b[0m 36.93   \u001b[0m | \u001b[0m 0.07496 \u001b[0m | \u001b[0m 40.29   \u001b[0m | \u001b[0m 0.3518  \u001b[0m | \u001b[0m 0.0582  \u001b[0m | \u001b[0m 0.6669  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 39, 'colsample_bytree': 0.8829309675129333, 'subsample': 0.9225389458917739, 'max_depth': 9, 'reg_alpha': 0.40557501036722243, 'reg_lambda': 0.35420180664538375, 'min_split_gain': 0.06285343925328274, 'min_child_weight': 36.60434032862998, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.839539\tvalid_0's binary_logloss: 0.517097\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.839539\tvalid_0's binary_logloss: 0.517097\n",
      "best_iter: 100\n",
      "roc_auc: 0.8395389449677171\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8395  \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 9.215   \u001b[0m | \u001b[0m 36.6    \u001b[0m | \u001b[0m 0.06285 \u001b[0m | \u001b[0m 38.82   \u001b[0m | \u001b[0m 0.4056  \u001b[0m | \u001b[0m 0.3542  \u001b[0m | \u001b[0m 0.9225  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 44, 'colsample_bytree': 0.68215321443245, 'subsample': 0.5771031698448831, 'max_depth': 8, 'reg_alpha': 0.3813425028899184, 'reg_lambda': 0.16713617383456836, 'min_split_gain': 0.054459964206156064, 'min_child_weight': 33.48434423033886, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.840796\tvalid_0's binary_logloss: 0.519988\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's auc: 0.840894\tvalid_0's binary_logloss: 0.520487\n",
      "best_iter: 98\n",
      "roc_auc: 0.8408941727820474\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8409  \u001b[0m | \u001b[0m 0.6822  \u001b[0m | \u001b[0m 8.144   \u001b[0m | \u001b[0m 33.48   \u001b[0m | \u001b[0m 0.05446 \u001b[0m | \u001b[0m 43.53   \u001b[0m | \u001b[0m 0.3813  \u001b[0m | \u001b[0m 0.1671  \u001b[0m | \u001b[0m 0.5771  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 31, 'colsample_bytree': 0.8029669550130942, 'subsample': 0.6551903227995404, 'max_depth': 7, 'reg_alpha': 0.320350739464454, 'reg_lambda': 0.123615644828728, 'min_split_gain': 0.09962054308027271, 'min_child_weight': 37.933441258045384, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.840402\tvalid_0's binary_logloss: 0.517698\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's auc: 0.840471\tvalid_0's binary_logloss: 0.517926\n",
      "best_iter: 99\n",
      "roc_auc: 0.8404711546818554\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8405  \u001b[0m | \u001b[0m 0.803   \u001b[0m | \u001b[0m 6.702   \u001b[0m | \u001b[0m 37.93   \u001b[0m | \u001b[0m 0.09962 \u001b[0m | \u001b[0m 30.73   \u001b[0m | \u001b[0m 0.3204  \u001b[0m | \u001b[0m 0.1236  \u001b[0m | \u001b[0m 0.6552  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 44, 'colsample_bytree': 0.7938575367700749, 'subsample': 0.5435940695073487, 'max_depth': 5, 'reg_alpha': 0.40445613739603187, 'reg_lambda': 0.30440629345289194, 'min_split_gain': 0.0076985060011006265, 'min_child_weight': 11.306184037494198, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.842298\tvalid_0's binary_logloss: 0.51514\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's auc: 0.842312\tvalid_0's binary_logloss: 0.515723\n",
      "best_iter: 98\n",
      "roc_auc: 0.8423118550637718\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.8423  \u001b[0m | \u001b[95m 0.7939  \u001b[0m | \u001b[95m 5.053   \u001b[0m | \u001b[95m 11.31   \u001b[0m | \u001b[95m 0.007699\u001b[0m | \u001b[95m 44.48   \u001b[0m | \u001b[95m 0.4045  \u001b[0m | \u001b[95m 0.3044  \u001b[0m | \u001b[95m 0.5436  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 37, 'colsample_bytree': 0.9306368742048947, 'subsample': 0.9299529005082734, 'max_depth': 7, 'reg_alpha': 0.19637994851163287, 'reg_lambda': 0.1750667333739045, 'min_split_gain': 0.058336100242476395, 'min_child_weight': 22.935679282856086, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.839625\tvalid_0's binary_logloss: 0.514414\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's auc: 0.839639\tvalid_0's binary_logloss: 0.514954\n",
      "best_iter: 98\n",
      "roc_auc: 0.8396393954134532\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8396  \u001b[0m | \u001b[0m 0.9306  \u001b[0m | \u001b[0m 7.481   \u001b[0m | \u001b[0m 22.94   \u001b[0m | \u001b[0m 0.05834 \u001b[0m | \u001b[0m 36.61   \u001b[0m | \u001b[0m 0.1964  \u001b[0m | \u001b[0m 0.1751  \u001b[0m | \u001b[0m 0.93    \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 43, 'colsample_bytree': 0.792985541295224, 'subsample': 0.6861540787879228, 'max_depth': 11, 'reg_alpha': 0.09854595285010953, 'reg_lambda': 0.34131373291389805, 'min_split_gain': 0.031081060947158217, 'min_child_weight': 28.510112111257893, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.841305\tvalid_0's binary_logloss: 0.517242\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.841305\tvalid_0's binary_logloss: 0.517242\n",
      "best_iter: 100\n",
      "roc_auc: 0.8413049047575061\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8413  \u001b[0m | \u001b[0m 0.793   \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 28.51   \u001b[0m | \u001b[0m 0.03108 \u001b[0m | \u001b[0m 42.59   \u001b[0m | \u001b[0m 0.09855 \u001b[0m | \u001b[0m 0.3413  \u001b[0m | \u001b[0m 0.6862  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 40, 'colsample_bytree': 0.9310790249680646, 'subsample': 0.6609310459039062, 'max_depth': 11, 'reg_alpha': 0.3913290728677325, 'reg_lambda': 0.3022751724502409, 'min_split_gain': 0.09171652572237717, 'min_child_weight': 36.89266443649109, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.839534\tvalid_0's binary_logloss: 0.516996\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's auc: 0.839547\tvalid_0's binary_logloss: 0.517262\n",
      "best_iter: 99\n",
      "roc_auc: 0.8395469081967109\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8395  \u001b[0m | \u001b[0m 0.9311  \u001b[0m | \u001b[0m 10.64   \u001b[0m | \u001b[0m 36.89   \u001b[0m | \u001b[0m 0.09172 \u001b[0m | \u001b[0m 40.23   \u001b[0m | \u001b[0m 0.3913  \u001b[0m | \u001b[0m 0.3023  \u001b[0m | \u001b[0m 0.6609  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 37, 'colsample_bytree': 0.6554150420073348, 'subsample': 0.9070428510477326, 'max_depth': 11, 'reg_alpha': 0.3116863781486092, 'reg_lambda': 0.2242081107031702, 'min_split_gain': 0.08873490442848239, 'min_child_weight': 46.056784622844944, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.840678\tvalid_0's binary_logloss: 0.521856\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's auc: 0.840726\tvalid_0's binary_logloss: 0.522094\n",
      "best_iter: 99\n",
      "roc_auc: 0.8407264330513138\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8407  \u001b[0m | \u001b[0m 0.6554  \u001b[0m | \u001b[0m 10.72   \u001b[0m | \u001b[0m 46.06   \u001b[0m | \u001b[0m 0.08873 \u001b[0m | \u001b[0m 36.54   \u001b[0m | \u001b[0m 0.3117  \u001b[0m | \u001b[0m 0.2242  \u001b[0m | \u001b[0m 0.907   \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 31, 'colsample_bytree': 0.9669330899630086, 'subsample': 0.59013614684125, 'max_depth': 6, 'reg_alpha': 0.41848510904031977, 'reg_lambda': 0.11061236380858464, 'min_split_gain': 0.06866426705998722, 'min_child_weight': 20.392767903558685, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.839249\tvalid_0's binary_logloss: 0.513928\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's auc: 0.839264\tvalid_0's binary_logloss: 0.514464\n",
      "best_iter: 98\n",
      "roc_auc: 0.8392638154059813\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8393  \u001b[0m | \u001b[0m 0.9669  \u001b[0m | \u001b[0m 5.938   \u001b[0m | \u001b[0m 20.39   \u001b[0m | \u001b[0m 0.06866 \u001b[0m | \u001b[0m 30.65   \u001b[0m | \u001b[0m 0.4185  \u001b[0m | \u001b[0m 0.1106  \u001b[0m | \u001b[0m 0.5901  \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "BO_lgb.maximize(init_points=5, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.8423118550637718,\n",
       " 'params': {'colsample_bytree': 0.7938575367700749,\n",
       "  'max_depth': 5.053212004372854,\n",
       "  'min_child_weight': 11.306184037494198,\n",
       "  'min_split_gain': 0.0076985060011006265,\n",
       "  'num_leaves': 44.47965199442237,\n",
       "  'reg_alpha': 0.40445613739603187,\n",
       "  'reg_lambda': 0.30440629345289194,\n",
       "  'subsample': 0.5435940695073487}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BO_lgb.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.757584\tvalid_0's binary_logloss: 0.688865\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.820464\tvalid_0's binary_logloss: 0.682817\n",
      "[3]\tvalid_0's auc: 0.827945\tvalid_0's binary_logloss: 0.677153\n",
      "[4]\tvalid_0's auc: 0.821919\tvalid_0's binary_logloss: 0.673323\n",
      "[5]\tvalid_0's auc: 0.827135\tvalid_0's binary_logloss: 0.66772\n",
      "[6]\tvalid_0's auc: 0.829388\tvalid_0's binary_logloss: 0.662284\n",
      "[7]\tvalid_0's auc: 0.831372\tvalid_0's binary_logloss: 0.657044\n",
      "[8]\tvalid_0's auc: 0.83202\tvalid_0's binary_logloss: 0.65217\n",
      "[9]\tvalid_0's auc: 0.832292\tvalid_0's binary_logloss: 0.647317\n",
      "[10]\tvalid_0's auc: 0.833469\tvalid_0's binary_logloss: 0.642749\n",
      "[11]\tvalid_0's auc: 0.833828\tvalid_0's binary_logloss: 0.638247\n",
      "[12]\tvalid_0's auc: 0.833744\tvalid_0's binary_logloss: 0.633942\n",
      "[13]\tvalid_0's auc: 0.834354\tvalid_0's binary_logloss: 0.629832\n",
      "[14]\tvalid_0's auc: 0.83447\tvalid_0's binary_logloss: 0.626155\n",
      "[15]\tvalid_0's auc: 0.834674\tvalid_0's binary_logloss: 0.623593\n",
      "[16]\tvalid_0's auc: 0.834447\tvalid_0's binary_logloss: 0.619803\n",
      "[17]\tvalid_0's auc: 0.835314\tvalid_0's binary_logloss: 0.616185\n",
      "[18]\tvalid_0's auc: 0.834876\tvalid_0's binary_logloss: 0.613809\n",
      "[19]\tvalid_0's auc: 0.835533\tvalid_0's binary_logloss: 0.6104\n",
      "[20]\tvalid_0's auc: 0.83582\tvalid_0's binary_logloss: 0.607067\n",
      "[21]\tvalid_0's auc: 0.835062\tvalid_0's binary_logloss: 0.60494\n",
      "[22]\tvalid_0's auc: 0.835531\tvalid_0's binary_logloss: 0.603126\n",
      "[23]\tvalid_0's auc: 0.836083\tvalid_0's binary_logloss: 0.600032\n",
      "[24]\tvalid_0's auc: 0.835302\tvalid_0's binary_logloss: 0.598124\n",
      "[25]\tvalid_0's auc: 0.835998\tvalid_0's binary_logloss: 0.595259\n",
      "[26]\tvalid_0's auc: 0.836302\tvalid_0's binary_logloss: 0.592401\n",
      "[27]\tvalid_0's auc: 0.836569\tvalid_0's binary_logloss: 0.589679\n",
      "[28]\tvalid_0's auc: 0.837046\tvalid_0's binary_logloss: 0.587048\n",
      "[29]\tvalid_0's auc: 0.836845\tvalid_0's binary_logloss: 0.585489\n",
      "[30]\tvalid_0's auc: 0.83743\tvalid_0's binary_logloss: 0.583105\n",
      "[31]\tvalid_0's auc: 0.837812\tvalid_0's binary_logloss: 0.580684\n",
      "[32]\tvalid_0's auc: 0.838159\tvalid_0's binary_logloss: 0.578446\n",
      "[33]\tvalid_0's auc: 0.838131\tvalid_0's binary_logloss: 0.576177\n",
      "[34]\tvalid_0's auc: 0.838268\tvalid_0's binary_logloss: 0.574935\n",
      "[35]\tvalid_0's auc: 0.838249\tvalid_0's binary_logloss: 0.572786\n",
      "[36]\tvalid_0's auc: 0.838455\tvalid_0's binary_logloss: 0.570668\n",
      "[37]\tvalid_0's auc: 0.838251\tvalid_0's binary_logloss: 0.569382\n",
      "[38]\tvalid_0's auc: 0.838395\tvalid_0's binary_logloss: 0.567464\n",
      "[39]\tvalid_0's auc: 0.838766\tvalid_0's binary_logloss: 0.566269\n",
      "[40]\tvalid_0's auc: 0.838839\tvalid_0's binary_logloss: 0.564528\n",
      "[41]\tvalid_0's auc: 0.838689\tvalid_0's binary_logloss: 0.562776\n",
      "[42]\tvalid_0's auc: 0.838926\tvalid_0's binary_logloss: 0.561041\n",
      "[43]\tvalid_0's auc: 0.838983\tvalid_0's binary_logloss: 0.559312\n",
      "[44]\tvalid_0's auc: 0.838822\tvalid_0's binary_logloss: 0.558228\n",
      "[45]\tvalid_0's auc: 0.838942\tvalid_0's binary_logloss: 0.556633\n",
      "[46]\tvalid_0's auc: 0.838991\tvalid_0's binary_logloss: 0.55509\n",
      "[47]\tvalid_0's auc: 0.839061\tvalid_0's binary_logloss: 0.553563\n",
      "[48]\tvalid_0's auc: 0.839171\tvalid_0's binary_logloss: 0.552125\n",
      "[49]\tvalid_0's auc: 0.839381\tvalid_0's binary_logloss: 0.550805\n",
      "[50]\tvalid_0's auc: 0.839398\tvalid_0's binary_logloss: 0.549964\n",
      "[51]\tvalid_0's auc: 0.839503\tvalid_0's binary_logloss: 0.548664\n",
      "[52]\tvalid_0's auc: 0.839441\tvalid_0's binary_logloss: 0.547426\n",
      "[53]\tvalid_0's auc: 0.839383\tvalid_0's binary_logloss: 0.546184\n",
      "[54]\tvalid_0's auc: 0.839458\tvalid_0's binary_logloss: 0.545374\n",
      "[55]\tvalid_0's auc: 0.839451\tvalid_0's binary_logloss: 0.544604\n",
      "[56]\tvalid_0's auc: 0.839455\tvalid_0's binary_logloss: 0.543395\n",
      "[57]\tvalid_0's auc: 0.839563\tvalid_0's binary_logloss: 0.54223\n",
      "[58]\tvalid_0's auc: 0.839526\tvalid_0's binary_logloss: 0.541074\n",
      "[59]\tvalid_0's auc: 0.839847\tvalid_0's binary_logloss: 0.540054\n",
      "[60]\tvalid_0's auc: 0.839919\tvalid_0's binary_logloss: 0.539422\n",
      "[61]\tvalid_0's auc: 0.840116\tvalid_0's binary_logloss: 0.5384\n",
      "[62]\tvalid_0's auc: 0.840204\tvalid_0's binary_logloss: 0.537276\n",
      "[63]\tvalid_0's auc: 0.840406\tvalid_0's binary_logloss: 0.536259\n",
      "[64]\tvalid_0's auc: 0.840351\tvalid_0's binary_logloss: 0.535696\n",
      "[65]\tvalid_0's auc: 0.840303\tvalid_0's binary_logloss: 0.534774\n",
      "[66]\tvalid_0's auc: 0.840293\tvalid_0's binary_logloss: 0.534204\n",
      "[67]\tvalid_0's auc: 0.84053\tvalid_0's binary_logloss: 0.533258\n",
      "[68]\tvalid_0's auc: 0.840589\tvalid_0's binary_logloss: 0.532353\n",
      "[69]\tvalid_0's auc: 0.840632\tvalid_0's binary_logloss: 0.531837\n",
      "[70]\tvalid_0's auc: 0.840663\tvalid_0's binary_logloss: 0.530996\n",
      "[71]\tvalid_0's auc: 0.840741\tvalid_0's binary_logloss: 0.530212\n",
      "[72]\tvalid_0's auc: 0.840778\tvalid_0's binary_logloss: 0.529437\n",
      "[73]\tvalid_0's auc: 0.840844\tvalid_0's binary_logloss: 0.528746\n",
      "[74]\tvalid_0's auc: 0.84111\tvalid_0's binary_logloss: 0.527961\n",
      "[75]\tvalid_0's auc: 0.841171\tvalid_0's binary_logloss: 0.527174\n",
      "[76]\tvalid_0's auc: 0.841175\tvalid_0's binary_logloss: 0.526589\n",
      "[77]\tvalid_0's auc: 0.841211\tvalid_0's binary_logloss: 0.525822\n",
      "[78]\tvalid_0's auc: 0.84127\tvalid_0's binary_logloss: 0.525117\n",
      "[79]\tvalid_0's auc: 0.84119\tvalid_0's binary_logloss: 0.52445\n",
      "[80]\tvalid_0's auc: 0.841254\tvalid_0's binary_logloss: 0.523908\n",
      "[81]\tvalid_0's auc: 0.841246\tvalid_0's binary_logloss: 0.523553\n",
      "[82]\tvalid_0's auc: 0.841306\tvalid_0's binary_logloss: 0.523178\n",
      "[83]\tvalid_0's auc: 0.841372\tvalid_0's binary_logloss: 0.522687\n",
      "[84]\tvalid_0's auc: 0.841453\tvalid_0's binary_logloss: 0.522358\n",
      "[85]\tvalid_0's auc: 0.84142\tvalid_0's binary_logloss: 0.521806\n",
      "[86]\tvalid_0's auc: 0.841599\tvalid_0's binary_logloss: 0.521296\n",
      "[87]\tvalid_0's auc: 0.841716\tvalid_0's binary_logloss: 0.52073\n",
      "[88]\tvalid_0's auc: 0.841725\tvalid_0's binary_logloss: 0.520143\n",
      "[89]\tvalid_0's auc: 0.841696\tvalid_0's binary_logloss: 0.519828\n",
      "[90]\tvalid_0's auc: 0.841816\tvalid_0's binary_logloss: 0.519313\n",
      "[91]\tvalid_0's auc: 0.841991\tvalid_0's binary_logloss: 0.518807\n",
      "[92]\tvalid_0's auc: 0.842116\tvalid_0's binary_logloss: 0.518317\n",
      "[93]\tvalid_0's auc: 0.842109\tvalid_0's binary_logloss: 0.517815\n",
      "[94]\tvalid_0's auc: 0.842106\tvalid_0's binary_logloss: 0.51741\n",
      "[95]\tvalid_0's auc: 0.842061\tvalid_0's binary_logloss: 0.516997\n",
      "[96]\tvalid_0's auc: 0.842191\tvalid_0's binary_logloss: 0.516554\n",
      "[97]\tvalid_0's auc: 0.842215\tvalid_0's binary_logloss: 0.516156\n",
      "[98]\tvalid_0's auc: 0.842312\tvalid_0's binary_logloss: 0.515723\n",
      "[99]\tvalid_0's auc: 0.842246\tvalid_0's binary_logloss: 0.515442\n",
      "[100]\tvalid_0's auc: 0.842298\tvalid_0's binary_logloss: 0.51514\n",
      "[101]\tvalid_0's auc: 0.842387\tvalid_0's binary_logloss: 0.514734\n",
      "[102]\tvalid_0's auc: 0.842384\tvalid_0's binary_logloss: 0.514413\n",
      "[103]\tvalid_0's auc: 0.842533\tvalid_0's binary_logloss: 0.514072\n",
      "[104]\tvalid_0's auc: 0.84256\tvalid_0's binary_logloss: 0.513779\n",
      "[105]\tvalid_0's auc: 0.842576\tvalid_0's binary_logloss: 0.513451\n",
      "[106]\tvalid_0's auc: 0.842679\tvalid_0's binary_logloss: 0.513128\n",
      "[107]\tvalid_0's auc: 0.842588\tvalid_0's binary_logloss: 0.512911\n",
      "[108]\tvalid_0's auc: 0.842605\tvalid_0's binary_logloss: 0.512667\n",
      "[109]\tvalid_0's auc: 0.842541\tvalid_0's binary_logloss: 0.512464\n",
      "[110]\tvalid_0's auc: 0.842518\tvalid_0's binary_logloss: 0.512261\n",
      "[111]\tvalid_0's auc: 0.842541\tvalid_0's binary_logloss: 0.511954\n",
      "[112]\tvalid_0's auc: 0.842575\tvalid_0's binary_logloss: 0.511685\n",
      "[113]\tvalid_0's auc: 0.842662\tvalid_0's binary_logloss: 0.511406\n",
      "[114]\tvalid_0's auc: 0.84259\tvalid_0's binary_logloss: 0.511191\n",
      "[115]\tvalid_0's auc: 0.842731\tvalid_0's binary_logloss: 0.510909\n",
      "[116]\tvalid_0's auc: 0.842782\tvalid_0's binary_logloss: 0.510611\n",
      "[117]\tvalid_0's auc: 0.842743\tvalid_0's binary_logloss: 0.510422\n",
      "[118]\tvalid_0's auc: 0.842674\tvalid_0's binary_logloss: 0.510265\n",
      "[119]\tvalid_0's auc: 0.842725\tvalid_0's binary_logloss: 0.51009\n",
      "[120]\tvalid_0's auc: 0.842831\tvalid_0's binary_logloss: 0.509859\n",
      "[121]\tvalid_0's auc: 0.842908\tvalid_0's binary_logloss: 0.509658\n",
      "[122]\tvalid_0's auc: 0.842908\tvalid_0's binary_logloss: 0.509501\n",
      "[123]\tvalid_0's auc: 0.84298\tvalid_0's binary_logloss: 0.509255\n",
      "[124]\tvalid_0's auc: 0.842914\tvalid_0's binary_logloss: 0.509066\n",
      "[125]\tvalid_0's auc: 0.842971\tvalid_0's binary_logloss: 0.508866\n",
      "[126]\tvalid_0's auc: 0.843\tvalid_0's binary_logloss: 0.508647\n",
      "[127]\tvalid_0's auc: 0.843075\tvalid_0's binary_logloss: 0.50851\n",
      "[128]\tvalid_0's auc: 0.843172\tvalid_0's binary_logloss: 0.50832\n",
      "[129]\tvalid_0's auc: 0.843255\tvalid_0's binary_logloss: 0.508104\n",
      "[130]\tvalid_0's auc: 0.84327\tvalid_0's binary_logloss: 0.507972\n",
      "[131]\tvalid_0's auc: 0.843339\tvalid_0's binary_logloss: 0.507815\n",
      "[132]\tvalid_0's auc: 0.843478\tvalid_0's binary_logloss: 0.50763\n",
      "[133]\tvalid_0's auc: 0.843462\tvalid_0's binary_logloss: 0.50747\n",
      "[134]\tvalid_0's auc: 0.843497\tvalid_0's binary_logloss: 0.507317\n",
      "[135]\tvalid_0's auc: 0.84356\tvalid_0's binary_logloss: 0.507175\n",
      "[136]\tvalid_0's auc: 0.843527\tvalid_0's binary_logloss: 0.507067\n",
      "[137]\tvalid_0's auc: 0.843569\tvalid_0's binary_logloss: 0.506905\n",
      "[138]\tvalid_0's auc: 0.843611\tvalid_0's binary_logloss: 0.506752\n",
      "[139]\tvalid_0's auc: 0.843575\tvalid_0's binary_logloss: 0.506624\n",
      "[140]\tvalid_0's auc: 0.843593\tvalid_0's binary_logloss: 0.506528\n",
      "[141]\tvalid_0's auc: 0.843706\tvalid_0's binary_logloss: 0.506421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142]\tvalid_0's auc: 0.84375\tvalid_0's binary_logloss: 0.506314\n",
      "[143]\tvalid_0's auc: 0.843807\tvalid_0's binary_logloss: 0.506217\n",
      "[144]\tvalid_0's auc: 0.843919\tvalid_0's binary_logloss: 0.506047\n",
      "[145]\tvalid_0's auc: 0.843991\tvalid_0's binary_logloss: 0.505915\n",
      "[146]\tvalid_0's auc: 0.843999\tvalid_0's binary_logloss: 0.505812\n",
      "[147]\tvalid_0's auc: 0.843962\tvalid_0's binary_logloss: 0.505717\n",
      "[148]\tvalid_0's auc: 0.844111\tvalid_0's binary_logloss: 0.505545\n",
      "[149]\tvalid_0's auc: 0.84421\tvalid_0's binary_logloss: 0.505403\n",
      "[150]\tvalid_0's auc: 0.844262\tvalid_0's binary_logloss: 0.505262\n",
      "[151]\tvalid_0's auc: 0.844288\tvalid_0's binary_logloss: 0.505138\n",
      "[152]\tvalid_0's auc: 0.844224\tvalid_0's binary_logloss: 0.505071\n",
      "[153]\tvalid_0's auc: 0.844164\tvalid_0's binary_logloss: 0.505006\n",
      "[154]\tvalid_0's auc: 0.844228\tvalid_0's binary_logloss: 0.504973\n",
      "[155]\tvalid_0's auc: 0.844269\tvalid_0's binary_logloss: 0.504922\n",
      "[156]\tvalid_0's auc: 0.844315\tvalid_0's binary_logloss: 0.504761\n",
      "[157]\tvalid_0's auc: 0.844313\tvalid_0's binary_logloss: 0.504665\n",
      "[158]\tvalid_0's auc: 0.844382\tvalid_0's binary_logloss: 0.504537\n",
      "[159]\tvalid_0's auc: 0.844419\tvalid_0's binary_logloss: 0.504453\n",
      "[160]\tvalid_0's auc: 0.84442\tvalid_0's binary_logloss: 0.504405\n",
      "[161]\tvalid_0's auc: 0.844442\tvalid_0's binary_logloss: 0.504323\n",
      "[162]\tvalid_0's auc: 0.84436\tvalid_0's binary_logloss: 0.504294\n",
      "[163]\tvalid_0's auc: 0.844352\tvalid_0's binary_logloss: 0.504321\n",
      "[164]\tvalid_0's auc: 0.84432\tvalid_0's binary_logloss: 0.504334\n",
      "[165]\tvalid_0's auc: 0.844354\tvalid_0's binary_logloss: 0.504242\n",
      "[166]\tvalid_0's auc: 0.844332\tvalid_0's binary_logloss: 0.504214\n",
      "[167]\tvalid_0's auc: 0.844424\tvalid_0's binary_logloss: 0.504153\n",
      "[168]\tvalid_0's auc: 0.844531\tvalid_0's binary_logloss: 0.50404\n",
      "[169]\tvalid_0's auc: 0.844544\tvalid_0's binary_logloss: 0.504001\n",
      "[170]\tvalid_0's auc: 0.844511\tvalid_0's binary_logloss: 0.503932\n",
      "[171]\tvalid_0's auc: 0.844491\tvalid_0's binary_logloss: 0.503876\n",
      "[172]\tvalid_0's auc: 0.844524\tvalid_0's binary_logloss: 0.503829\n",
      "[173]\tvalid_0's auc: 0.844595\tvalid_0's binary_logloss: 0.50373\n",
      "[174]\tvalid_0's auc: 0.844667\tvalid_0's binary_logloss: 0.503637\n",
      "[175]\tvalid_0's auc: 0.844669\tvalid_0's binary_logloss: 0.503604\n",
      "[176]\tvalid_0's auc: 0.844719\tvalid_0's binary_logloss: 0.503537\n",
      "[177]\tvalid_0's auc: 0.844803\tvalid_0's binary_logloss: 0.503448\n",
      "[178]\tvalid_0's auc: 0.844801\tvalid_0's binary_logloss: 0.503348\n",
      "[179]\tvalid_0's auc: 0.844785\tvalid_0's binary_logloss: 0.503322\n",
      "[180]\tvalid_0's auc: 0.84479\tvalid_0's binary_logloss: 0.503315\n",
      "[181]\tvalid_0's auc: 0.84488\tvalid_0's binary_logloss: 0.503208\n",
      "[182]\tvalid_0's auc: 0.844891\tvalid_0's binary_logloss: 0.503216\n",
      "[183]\tvalid_0's auc: 0.84485\tvalid_0's binary_logloss: 0.503184\n",
      "[184]\tvalid_0's auc: 0.844895\tvalid_0's binary_logloss: 0.503139\n",
      "[185]\tvalid_0's auc: 0.845016\tvalid_0's binary_logloss: 0.503011\n",
      "[186]\tvalid_0's auc: 0.845068\tvalid_0's binary_logloss: 0.502927\n",
      "[187]\tvalid_0's auc: 0.845091\tvalid_0's binary_logloss: 0.502871\n",
      "[188]\tvalid_0's auc: 0.845093\tvalid_0's binary_logloss: 0.50286\n",
      "[189]\tvalid_0's auc: 0.845151\tvalid_0's binary_logloss: 0.502753\n",
      "[190]\tvalid_0's auc: 0.845144\tvalid_0's binary_logloss: 0.502761\n",
      "[191]\tvalid_0's auc: 0.845153\tvalid_0's binary_logloss: 0.502757\n",
      "[192]\tvalid_0's auc: 0.84527\tvalid_0's binary_logloss: 0.502636\n",
      "[193]\tvalid_0's auc: 0.845253\tvalid_0's binary_logloss: 0.502646\n",
      "[194]\tvalid_0's auc: 0.845333\tvalid_0's binary_logloss: 0.502561\n",
      "[195]\tvalid_0's auc: 0.84535\tvalid_0's binary_logloss: 0.502528\n",
      "[196]\tvalid_0's auc: 0.845335\tvalid_0's binary_logloss: 0.50254\n",
      "[197]\tvalid_0's auc: 0.845422\tvalid_0's binary_logloss: 0.502448\n",
      "[198]\tvalid_0's auc: 0.845401\tvalid_0's binary_logloss: 0.502463\n",
      "[199]\tvalid_0's auc: 0.845442\tvalid_0's binary_logloss: 0.502369\n",
      "[200]\tvalid_0's auc: 0.84542\tvalid_0's binary_logloss: 0.50239\n",
      "[201]\tvalid_0's auc: 0.845443\tvalid_0's binary_logloss: 0.502305\n",
      "[202]\tvalid_0's auc: 0.845422\tvalid_0's binary_logloss: 0.502304\n",
      "[203]\tvalid_0's auc: 0.845462\tvalid_0's binary_logloss: 0.50223\n",
      "[204]\tvalid_0's auc: 0.845423\tvalid_0's binary_logloss: 0.502245\n",
      "[205]\tvalid_0's auc: 0.845443\tvalid_0's binary_logloss: 0.502227\n",
      "[206]\tvalid_0's auc: 0.845427\tvalid_0's binary_logloss: 0.502223\n",
      "[207]\tvalid_0's auc: 0.845392\tvalid_0's binary_logloss: 0.502248\n",
      "[208]\tvalid_0's auc: 0.845396\tvalid_0's binary_logloss: 0.502177\n",
      "[209]\tvalid_0's auc: 0.845446\tvalid_0's binary_logloss: 0.502095\n",
      "[210]\tvalid_0's auc: 0.845455\tvalid_0's binary_logloss: 0.502041\n",
      "[211]\tvalid_0's auc: 0.845462\tvalid_0's binary_logloss: 0.501991\n",
      "[212]\tvalid_0's auc: 0.845473\tvalid_0's binary_logloss: 0.501955\n",
      "[213]\tvalid_0's auc: 0.845481\tvalid_0's binary_logloss: 0.501934\n",
      "[214]\tvalid_0's auc: 0.845456\tvalid_0's binary_logloss: 0.501876\n",
      "[215]\tvalid_0's auc: 0.845463\tvalid_0's binary_logloss: 0.501883\n",
      "[216]\tvalid_0's auc: 0.845459\tvalid_0's binary_logloss: 0.501864\n",
      "[217]\tvalid_0's auc: 0.845484\tvalid_0's binary_logloss: 0.501818\n",
      "[218]\tvalid_0's auc: 0.845508\tvalid_0's binary_logloss: 0.501786\n",
      "[219]\tvalid_0's auc: 0.845503\tvalid_0's binary_logloss: 0.501746\n",
      "[220]\tvalid_0's auc: 0.845578\tvalid_0's binary_logloss: 0.501705\n",
      "[221]\tvalid_0's auc: 0.84552\tvalid_0's binary_logloss: 0.501642\n",
      "[222]\tvalid_0's auc: 0.845584\tvalid_0's binary_logloss: 0.501655\n",
      "[223]\tvalid_0's auc: 0.84557\tvalid_0's binary_logloss: 0.501642\n",
      "[224]\tvalid_0's auc: 0.845561\tvalid_0's binary_logloss: 0.501664\n",
      "[225]\tvalid_0's auc: 0.845568\tvalid_0's binary_logloss: 0.501679\n",
      "[226]\tvalid_0's auc: 0.845552\tvalid_0's binary_logloss: 0.501678\n",
      "[227]\tvalid_0's auc: 0.845499\tvalid_0's binary_logloss: 0.501666\n",
      "[228]\tvalid_0's auc: 0.845517\tvalid_0's binary_logloss: 0.501664\n",
      "[229]\tvalid_0's auc: 0.845503\tvalid_0's binary_logloss: 0.501661\n",
      "[230]\tvalid_0's auc: 0.845467\tvalid_0's binary_logloss: 0.501674\n",
      "[231]\tvalid_0's auc: 0.845526\tvalid_0's binary_logloss: 0.501609\n",
      "[232]\tvalid_0's auc: 0.845508\tvalid_0's binary_logloss: 0.501634\n",
      "[233]\tvalid_0's auc: 0.845491\tvalid_0's binary_logloss: 0.50159\n",
      "[234]\tvalid_0's auc: 0.845491\tvalid_0's binary_logloss: 0.501534\n",
      "[235]\tvalid_0's auc: 0.845537\tvalid_0's binary_logloss: 0.501486\n",
      "[236]\tvalid_0's auc: 0.845494\tvalid_0's binary_logloss: 0.501483\n",
      "[237]\tvalid_0's auc: 0.84554\tvalid_0's binary_logloss: 0.501427\n",
      "[238]\tvalid_0's auc: 0.84548\tvalid_0's binary_logloss: 0.501464\n",
      "[239]\tvalid_0's auc: 0.845538\tvalid_0's binary_logloss: 0.501394\n",
      "[240]\tvalid_0's auc: 0.845587\tvalid_0's binary_logloss: 0.501342\n",
      "[241]\tvalid_0's auc: 0.845596\tvalid_0's binary_logloss: 0.501321\n",
      "[242]\tvalid_0's auc: 0.845622\tvalid_0's binary_logloss: 0.501288\n",
      "[243]\tvalid_0's auc: 0.845647\tvalid_0's binary_logloss: 0.50129\n",
      "[244]\tvalid_0's auc: 0.845644\tvalid_0's binary_logloss: 0.501277\n",
      "[245]\tvalid_0's auc: 0.845622\tvalid_0's binary_logloss: 0.501241\n",
      "[246]\tvalid_0's auc: 0.845691\tvalid_0's binary_logloss: 0.501185\n",
      "[247]\tvalid_0's auc: 0.845696\tvalid_0's binary_logloss: 0.501168\n",
      "[248]\tvalid_0's auc: 0.845745\tvalid_0's binary_logloss: 0.501121\n",
      "[249]\tvalid_0's auc: 0.845779\tvalid_0's binary_logloss: 0.501085\n",
      "[250]\tvalid_0's auc: 0.845808\tvalid_0's binary_logloss: 0.501043\n",
      "[251]\tvalid_0's auc: 0.845832\tvalid_0's binary_logloss: 0.501016\n",
      "[252]\tvalid_0's auc: 0.845836\tvalid_0's binary_logloss: 0.501005\n",
      "[253]\tvalid_0's auc: 0.84575\tvalid_0's binary_logloss: 0.501039\n",
      "[254]\tvalid_0's auc: 0.845751\tvalid_0's binary_logloss: 0.50102\n",
      "[255]\tvalid_0's auc: 0.84569\tvalid_0's binary_logloss: 0.501025\n",
      "[256]\tvalid_0's auc: 0.845682\tvalid_0's binary_logloss: 0.501022\n",
      "[257]\tvalid_0's auc: 0.845682\tvalid_0's binary_logloss: 0.501038\n",
      "[258]\tvalid_0's auc: 0.845712\tvalid_0's binary_logloss: 0.501042\n",
      "[259]\tvalid_0's auc: 0.845714\tvalid_0's binary_logloss: 0.501003\n",
      "[260]\tvalid_0's auc: 0.845683\tvalid_0's binary_logloss: 0.501014\n",
      "[261]\tvalid_0's auc: 0.84571\tvalid_0's binary_logloss: 0.500999\n",
      "[262]\tvalid_0's auc: 0.845708\tvalid_0's binary_logloss: 0.50099\n",
      "[263]\tvalid_0's auc: 0.845689\tvalid_0's binary_logloss: 0.501002\n",
      "[264]\tvalid_0's auc: 0.845709\tvalid_0's binary_logloss: 0.500999\n",
      "[265]\tvalid_0's auc: 0.845729\tvalid_0's binary_logloss: 0.500977\n",
      "[266]\tvalid_0's auc: 0.845746\tvalid_0's binary_logloss: 0.501004\n",
      "[267]\tvalid_0's auc: 0.845722\tvalid_0's binary_logloss: 0.501017\n",
      "[268]\tvalid_0's auc: 0.845757\tvalid_0's binary_logloss: 0.50103\n",
      "[269]\tvalid_0's auc: 0.845777\tvalid_0's binary_logloss: 0.501007\n",
      "[270]\tvalid_0's auc: 0.84579\tvalid_0's binary_logloss: 0.500962\n",
      "[271]\tvalid_0's auc: 0.845768\tvalid_0's binary_logloss: 0.500944\n",
      "[272]\tvalid_0's auc: 0.845726\tvalid_0's binary_logloss: 0.500989\n",
      "[273]\tvalid_0's auc: 0.845743\tvalid_0's binary_logloss: 0.500969\n",
      "[274]\tvalid_0's auc: 0.845735\tvalid_0's binary_logloss: 0.500973\n",
      "[275]\tvalid_0's auc: 0.845762\tvalid_0's binary_logloss: 0.500957\n",
      "[276]\tvalid_0's auc: 0.845751\tvalid_0's binary_logloss: 0.500996\n",
      "[277]\tvalid_0's auc: 0.845763\tvalid_0's binary_logloss: 0.500974\n",
      "[278]\tvalid_0's auc: 0.845754\tvalid_0's binary_logloss: 0.500965\n",
      "[279]\tvalid_0's auc: 0.845735\tvalid_0's binary_logloss: 0.500961\n",
      "[280]\tvalid_0's auc: 0.84572\tvalid_0's binary_logloss: 0.500927\n",
      "[281]\tvalid_0's auc: 0.845703\tvalid_0's binary_logloss: 0.500932\n",
      "[282]\tvalid_0's auc: 0.845629\tvalid_0's binary_logloss: 0.500957\n",
      "[283]\tvalid_0's auc: 0.845628\tvalid_0's binary_logloss: 0.500948\n",
      "[284]\tvalid_0's auc: 0.845576\tvalid_0's binary_logloss: 0.501043\n",
      "[285]\tvalid_0's auc: 0.845574\tvalid_0's binary_logloss: 0.501027\n",
      "[286]\tvalid_0's auc: 0.845572\tvalid_0's binary_logloss: 0.501018\n",
      "[287]\tvalid_0's auc: 0.845553\tvalid_0's binary_logloss: 0.501026\n",
      "[288]\tvalid_0's auc: 0.84553\tvalid_0's binary_logloss: 0.501029\n",
      "[289]\tvalid_0's auc: 0.845515\tvalid_0's binary_logloss: 0.501073\n",
      "[290]\tvalid_0's auc: 0.845509\tvalid_0's binary_logloss: 0.501077\n",
      "[291]\tvalid_0's auc: 0.845498\tvalid_0's binary_logloss: 0.501061\n",
      "[292]\tvalid_0's auc: 0.845469\tvalid_0's binary_logloss: 0.501071\n",
      "[293]\tvalid_0's auc: 0.845471\tvalid_0's binary_logloss: 0.501068\n",
      "[294]\tvalid_0's auc: 0.845441\tvalid_0's binary_logloss: 0.501132\n",
      "[295]\tvalid_0's auc: 0.845438\tvalid_0's binary_logloss: 0.501101\n",
      "[296]\tvalid_0's auc: 0.845464\tvalid_0's binary_logloss: 0.501078\n",
      "[297]\tvalid_0's auc: 0.845469\tvalid_0's binary_logloss: 0.501067\n",
      "[298]\tvalid_0's auc: 0.845431\tvalid_0's binary_logloss: 0.501079\n",
      "[299]\tvalid_0's auc: 0.845438\tvalid_0's binary_logloss: 0.501067\n",
      "[300]\tvalid_0's auc: 0.845457\tvalid_0's binary_logloss: 0.501076\n",
      "[301]\tvalid_0's auc: 0.845451\tvalid_0's binary_logloss: 0.501065\n",
      "[302]\tvalid_0's auc: 0.845434\tvalid_0's binary_logloss: 0.501102\n",
      "[303]\tvalid_0's auc: 0.845417\tvalid_0's binary_logloss: 0.50108\n",
      "[304]\tvalid_0's auc: 0.845387\tvalid_0's binary_logloss: 0.501051\n",
      "[305]\tvalid_0's auc: 0.845407\tvalid_0's binary_logloss: 0.50103\n",
      "[306]\tvalid_0's auc: 0.845416\tvalid_0's binary_logloss: 0.501026\n",
      "[307]\tvalid_0's auc: 0.845383\tvalid_0's binary_logloss: 0.50106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308]\tvalid_0's auc: 0.845372\tvalid_0's binary_logloss: 0.501062\n",
      "[309]\tvalid_0's auc: 0.845318\tvalid_0's binary_logloss: 0.501084\n",
      "[310]\tvalid_0's auc: 0.845329\tvalid_0's binary_logloss: 0.501077\n",
      "[311]\tvalid_0's auc: 0.84532\tvalid_0's binary_logloss: 0.501044\n",
      "[312]\tvalid_0's auc: 0.845335\tvalid_0's binary_logloss: 0.501074\n",
      "[313]\tvalid_0's auc: 0.845352\tvalid_0's binary_logloss: 0.501072\n",
      "[314]\tvalid_0's auc: 0.845329\tvalid_0's binary_logloss: 0.501065\n",
      "[315]\tvalid_0's auc: 0.84529\tvalid_0's binary_logloss: 0.501024\n",
      "[316]\tvalid_0's auc: 0.845302\tvalid_0's binary_logloss: 0.501013\n",
      "[317]\tvalid_0's auc: 0.845284\tvalid_0's binary_logloss: 0.500997\n",
      "[318]\tvalid_0's auc: 0.845288\tvalid_0's binary_logloss: 0.500984\n",
      "[319]\tvalid_0's auc: 0.845247\tvalid_0's binary_logloss: 0.501023\n",
      "[320]\tvalid_0's auc: 0.845202\tvalid_0's binary_logloss: 0.501049\n",
      "[321]\tvalid_0's auc: 0.845189\tvalid_0's binary_logloss: 0.501036\n",
      "[322]\tvalid_0's auc: 0.845198\tvalid_0's binary_logloss: 0.501022\n",
      "[323]\tvalid_0's auc: 0.845161\tvalid_0's binary_logloss: 0.501056\n",
      "[324]\tvalid_0's auc: 0.845175\tvalid_0's binary_logloss: 0.501072\n",
      "[325]\tvalid_0's auc: 0.845147\tvalid_0's binary_logloss: 0.501063\n",
      "[326]\tvalid_0's auc: 0.845146\tvalid_0's binary_logloss: 0.50104\n",
      "[327]\tvalid_0's auc: 0.845128\tvalid_0's binary_logloss: 0.5011\n",
      "[328]\tvalid_0's auc: 0.84508\tvalid_0's binary_logloss: 0.50109\n",
      "[329]\tvalid_0's auc: 0.845118\tvalid_0's binary_logloss: 0.501058\n",
      "[330]\tvalid_0's auc: 0.845111\tvalid_0's binary_logloss: 0.501044\n",
      "[331]\tvalid_0's auc: 0.845113\tvalid_0's binary_logloss: 0.50102\n",
      "[332]\tvalid_0's auc: 0.845112\tvalid_0's binary_logloss: 0.501038\n",
      "[333]\tvalid_0's auc: 0.845087\tvalid_0's binary_logloss: 0.501044\n",
      "[334]\tvalid_0's auc: 0.84507\tvalid_0's binary_logloss: 0.501017\n",
      "[335]\tvalid_0's auc: 0.845015\tvalid_0's binary_logloss: 0.501045\n",
      "[336]\tvalid_0's auc: 0.844997\tvalid_0's binary_logloss: 0.501077\n",
      "[337]\tvalid_0's auc: 0.844983\tvalid_0's binary_logloss: 0.501087\n",
      "[338]\tvalid_0's auc: 0.845001\tvalid_0's binary_logloss: 0.50108\n",
      "[339]\tvalid_0's auc: 0.844999\tvalid_0's binary_logloss: 0.501046\n",
      "[340]\tvalid_0's auc: 0.844963\tvalid_0's binary_logloss: 0.501019\n",
      "[341]\tvalid_0's auc: 0.844944\tvalid_0's binary_logloss: 0.501024\n",
      "[342]\tvalid_0's auc: 0.844942\tvalid_0's binary_logloss: 0.500993\n",
      "[343]\tvalid_0's auc: 0.844914\tvalid_0's binary_logloss: 0.500999\n",
      "[344]\tvalid_0's auc: 0.844943\tvalid_0's binary_logloss: 0.500991\n",
      "[345]\tvalid_0's auc: 0.84496\tvalid_0's binary_logloss: 0.501\n",
      "[346]\tvalid_0's auc: 0.844959\tvalid_0's binary_logloss: 0.501009\n",
      "[347]\tvalid_0's auc: 0.844947\tvalid_0's binary_logloss: 0.501\n",
      "[348]\tvalid_0's auc: 0.844941\tvalid_0's binary_logloss: 0.501003\n",
      "[349]\tvalid_0's auc: 0.844899\tvalid_0's binary_logloss: 0.501017\n",
      "[350]\tvalid_0's auc: 0.844869\tvalid_0's binary_logloss: 0.501108\n",
      "[351]\tvalid_0's auc: 0.844865\tvalid_0's binary_logloss: 0.501104\n",
      "[352]\tvalid_0's auc: 0.844854\tvalid_0's binary_logloss: 0.501115\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's auc: 0.845836\tvalid_0's binary_logloss: 0.501005\n",
      "ROC AUC: 0.8458\n"
     ]
    }
   ],
   "source": [
    "max_params = BO_lgb.max['params']\n",
    "\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "\n",
    "lgbm_clf_bayes_best = LGBMClassifier(n_estimators=1000, learning_rate=0.02, **max_params)\n",
    "\n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_clf_bayes_best.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"auc\", eval_set=evals,\n",
    "                verbose=True)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf_bayes_best.predict_proba(X_test)[:,1],average='macro')\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.7938575367700749, learning_rate=0.02,\n",
       "               max_depth=5, min_child_weight=11.306184037494198,\n",
       "               min_split_gain=0.0076985060011006265, n_estimators=1000,\n",
       "               num_leaves=44, reg_alpha=0.40445613739603187,\n",
       "               reg_lambda=0.30440629345289194, subsample=0.5435940695073487)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf_bayes_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.7938575367700749, learning_rate=0.02,\n",
       "               max_depth=5, min_child_weight=11.306184037494198,\n",
       "               min_split_gain=0.0076985060011006265, n_estimators=1000,\n",
       "               num_leaves=44, reg_alpha=0.40445613739603187,\n",
       "               reg_lambda=0.30440629345289194, subsample=0.5435940695073487)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf_bayes_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1_score = metrics.f1_score(y_test, pred)\n",
    "    roc_auc_score = metrics.roc_auc_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1_score: {2: 4f}, ROC_AUC_Score: {3: 4f}'.format(accuracy , precision ,recall, f1_score, roc_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape : (15204, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.69810474 0.30189526]\n",
      " [0.95620636 0.04379364]\n",
      " [0.85403558 0.14596442]]\n",
      "두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.69810474 0.30189526 0.69810474 0.30189526]\n",
      " [0.95620636 0.04379364 0.95620636 0.04379364]\n",
      " [0.85403558 0.14596442 0.85403558 0.14596442]]\n"
     ]
    }
   ],
   "source": [
    "## 1 ##\n",
    "\n",
    "pred_proba = lgbm_clf_bayes_best.predict_proba(X_test) ##\n",
    "pred  = lgbm_clf_bayes_best.predict_proba(X_test) ##\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,2)],axis=1)\n",
    "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[11135  3467]\n",
      " [  137   465]]\n",
      "정확도: 0.7630, 정밀도: 0.1183, 재현율: 0.7724, F1_score:  0.772425, ROC_AUC_Score:  0.205117\n"
     ]
    }
   ],
   "source": [
    "## 2\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Binarizer의 threshold 설정값. 분류 결정 임곗값임.  \n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba( ) 반환값의 두번째 컬럼 , 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lgbm_clf_bayes_best.predict_proba(X_test)[:, 1] ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "    \n",
    "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "    \n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "precision_recall_curve_plot(y_test, lgbm_clf_bayes_best.predict_proba(X_test)[:, 1] ) ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.819, 0.2789)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Find_threshold(model, X_test, y_test):\n",
    "    thresholds = np.arange(0,1,0.001)\n",
    "    threshold_count = []\n",
    "    pred_proba=model.predict_proba(X_test)\n",
    "    pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "    for threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=threshold)\n",
    "        model_cl_pred = binarizer.transform(pred_proba_1)\n",
    "        threshold_count.append([threshold, metrics.f1_score(model_cl_pred, y_test)])\n",
    "\n",
    "    MAX=thresholds[np.array(threshold_count)[:,1].argmax()]\n",
    "    \n",
    "    thresholds = np.arange(MAX-0.05,MAX+0.05,0.005)\n",
    "    threshold_count = []\n",
    "    for threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=threshold)\n",
    "        model_cl_pred = binarizer.transform(pred_proba_1)\n",
    "        #threshold_count.append([threshold, metrics.f1_score(log_cl_pred, y_test)])\n",
    "        #print('threshold: {0:.4f}, f1_score: {1:.4f}'.format(threshold,metrics.f1_score(model_cl_pred, y_test)))\n",
    "        threshold_count.append([threshold, metrics.f1_score(model_cl_pred, y_test)])\n",
    "    \n",
    "    return np.round(thresholds[np.array(threshold_count)[:,1].argmax()],4), np.round(metrics.f1_score(Binarizer(threshold=thresholds[np.array(threshold_count)[:,1].argmax()]).transform(pred_proba_1), y_test),4)\n",
    "\n",
    "Find_threshold(lgbm_clf_bayes_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[13649   953]\n",
      " [  350   252]]\n",
      "정확도: 0.9143, 정밀도: 0.2091, 재현율: 0.4186, F1_score:  0.418605, ROC_AUC_Score:  0.278915\n"
     ]
    }
   ],
   "source": [
    "# Binarizer의 베스트 threshold 설정값 지정 \n",
    "\n",
    "custom_threshold = 0.819\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test , custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 오버 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borderline SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, stratify = y)\n",
    "\n",
    "# 분류학습시 stratify = target으로 설정해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = BorderlineSMOTE(n_jobs=-1).fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 Shape:(116820, 369), 테스트 세트 Shape:(15204, 369)\n",
      " 학습 세트 레이블 값 분포 비율\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      " 테스트 세트 레이블 값 분포 비율\n",
      "0    0.960405\n",
      "1    0.039595\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 추후 오버,언더,하이드리브 샘플링 적용시 레이블 값 분포를 보기위한 코드.\n",
    "\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape , X_test.shape))\n",
    "\n",
    "print(' 학습 세트 레이블 값 분포 비율')\n",
    "print(y_train.value_counts()/train_cnt)\n",
    "print('\\n 테스트 세트 레이블 값 분포 비율')\n",
    "print(y_test.value_counts()/test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaysianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_params = {\n",
    "    'num_leaves': (24, 45),\n",
    "    'colsample_bytree':(0.5, 1), \n",
    "    'subsample': (0.5, 1),\n",
    "    'max_depth': (4, 12),\n",
    "    'reg_alpha': (0, 0.5),\n",
    "    'reg_lambda': (0, 0.5), \n",
    "    'min_split_gain': (0.001, 0.1),\n",
    "    'min_child_weight':(5, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def lgb_roc_eval(num_leaves, colsample_bytree, subsample, max_depth, reg_alpha, reg_lambda, min_split_gain, min_child_weight):\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimator\":200,\n",
    "        \"learning_rate\":0.02,\n",
    "        'num_leaves': int(round(num_leaves)),\n",
    "        'colsample_bytree': colsample_bytree, \n",
    "        'subsample': subsample,\n",
    "        'max_depth': int(round(max_depth)),\n",
    "        'reg_alpha': reg_alpha,\n",
    "        'reg_lambda': reg_lambda, \n",
    "        'min_split_gain': min_split_gain,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    print(\"params:\", params)\n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=30, eval_metric=\"auc\", verbose=100 )\n",
    "    best_iter = lgb_model.best_iteration_\n",
    "    print('best_iter:', best_iter)\n",
    "    valid_proba = lgb_model.predict_proba(X_test, num_iteration=best_iter)[:, 1]\n",
    "    roc_preds = roc_auc_score(y_test, valid_proba)\n",
    "    print('roc_auc:', roc_preds)\n",
    "    return roc_preds\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "BO_lgb = BayesianOptimization(lgb_roc_eval, bayes_params, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | max_depth | min_ch... | min_sp... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 33, 'colsample_bytree': 0.7744067519636624, 'subsample': 0.9458865003910399, 'max_depth': 10, 'reg_alpha': 0.32294705653332806, 'reg_lambda': 0.21879360563134626, 'min_split_gain': 0.05494343511669279, 'min_child_weight': 32.12435192322397, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.818864\tvalid_0's binary_logloss: 0.486113\n",
      "best_iter: 27\n",
      "roc_auc: 0.8188638997707045\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8189  \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 9.722   \u001b[0m | \u001b[0m 32.12   \u001b[0m | \u001b[0m 0.05494 \u001b[0m | \u001b[0m 32.9    \u001b[0m | \u001b[0m 0.3229  \u001b[0m | \u001b[0m 0.2188  \u001b[0m | \u001b[0m 0.9459  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 36, 'colsample_bytree': 0.9818313802505146, 'subsample': 0.5435646498507704, 'max_depth': 7, 'reg_alpha': 0.4627983191463305, 'reg_lambda': 0.03551802909894347, 'min_split_gain': 0.05336059705553755, 'min_child_weight': 40.627626713719906, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.820884\tvalid_0's binary_logloss: 0.329581\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[77]\tvalid_0's auc: 0.822382\tvalid_0's binary_logloss: 0.353743\n",
      "best_iter: 77\n",
      "roc_auc: 0.8223822249807857\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8224  \u001b[0m | \u001b[95m 0.9818  \u001b[0m | \u001b[95m 7.068   \u001b[0m | \u001b[95m 40.63   \u001b[0m | \u001b[95m 0.05336 \u001b[0m | \u001b[95m 35.93   \u001b[0m | \u001b[95m 0.4628  \u001b[0m | \u001b[95m 0.03552 \u001b[0m | \u001b[95m 0.5436  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 45, 'colsample_bytree': 0.5101091987201629, 'subsample': 0.8902645881432277, 'max_depth': 11, 'reg_alpha': 0.3995792821083618, 'reg_lambda': 0.23073968112646592, 'min_split_gain': 0.08713120267643511, 'min_child_weight': 40.01705379274327, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.814153\tvalid_0's binary_logloss: 0.313534\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[93]\tvalid_0's auc: 0.814546\tvalid_0's binary_logloss: 0.321589\n",
      "best_iter: 93\n",
      "roc_auc: 0.8145462370102671\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8145  \u001b[0m | \u001b[0m 0.5101  \u001b[0m | \u001b[0m 10.66   \u001b[0m | \u001b[0m 40.02   \u001b[0m | \u001b[0m 0.08713 \u001b[0m | \u001b[0m 44.55   \u001b[0m | \u001b[0m 0.3996  \u001b[0m | \u001b[0m 0.2307  \u001b[0m | \u001b[0m 0.8903  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 35, 'colsample_bytree': 0.5591372129344666, 'subsample': 0.8871168447171083, 'max_depth': 9, 'reg_alpha': 0.2073309699952618, 'reg_lambda': 0.13227780605231348, 'min_split_gain': 0.09452222278790881, 'min_child_weight': 11.450897933407088, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.816643\tvalid_0's binary_logloss: 0.320037\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.816643\tvalid_0's binary_logloss: 0.320037\n",
      "best_iter: 100\n",
      "roc_auc: 0.8166429552043342\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8166  \u001b[0m | \u001b[0m 0.5591  \u001b[0m | \u001b[0m 9.119   \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 0.09452 \u001b[0m | \u001b[0m 34.96   \u001b[0m | \u001b[0m 0.2073  \u001b[0m | \u001b[0m 0.1323  \u001b[0m | \u001b[0m 0.8871  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 37, 'colsample_bytree': 0.7280751661082743, 'subsample': 0.8409101495517417, 'max_depth': 9, 'reg_alpha': 0.30846699843737846, 'reg_lambda': 0.4718740392573121, 'min_split_gain': 0.062145914210511834, 'min_child_weight': 5.845541019635982, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.822424\tvalid_0's binary_logloss: 0.316807\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.822424\tvalid_0's binary_logloss: 0.316807\n",
      "best_iter: 100\n",
      "roc_auc: 0.8224237475319678\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.8224  \u001b[0m | \u001b[95m 0.7281  \u001b[0m | \u001b[95m 8.547   \u001b[0m | \u001b[95m 5.846   \u001b[0m | \u001b[95m 0.06215 \u001b[0m | \u001b[95m 36.85   \u001b[0m | \u001b[95m 0.3085  \u001b[0m | \u001b[95m 0.4719  \u001b[0m | \u001b[95m 0.8409  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 40, 'colsample_bytree': 0.8071874312473927, 'subsample': 0.6669384227592721, 'max_depth': 11, 'reg_alpha': 0.3518457494436385, 'reg_lambda': 0.0582019311377151, 'min_split_gain': 0.07495751902247628, 'min_child_weight': 36.927528592278506, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.818421\tvalid_0's binary_logloss: 0.492735\n",
      "best_iter: 25\n",
      "roc_auc: 0.8184214855198919\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8184  \u001b[0m | \u001b[0m 0.8072  \u001b[0m | \u001b[0m 10.54   \u001b[0m | \u001b[0m 36.93   \u001b[0m | \u001b[0m 0.07496 \u001b[0m | \u001b[0m 40.29   \u001b[0m | \u001b[0m 0.3518  \u001b[0m | \u001b[0m 0.0582  \u001b[0m | \u001b[0m 0.6669  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 36, 'colsample_bytree': 0.8607638434997915, 'subsample': 0.5232923229014805, 'max_depth': 9, 'reg_alpha': 0.22904634543928865, 'reg_lambda': 0.2856891950798225, 'min_split_gain': 0.005519743935817997, 'min_child_weight': 6.300312897977337, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.821713\tvalid_0's binary_logloss: 0.493845\n",
      "best_iter: 25\n",
      "roc_auc: 0.8217131999848927\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8217  \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 8.929   \u001b[0m | \u001b[0m 6.3     \u001b[0m | \u001b[0m 0.00552 \u001b[0m | \u001b[0m 36.1    \u001b[0m | \u001b[0m 0.229   \u001b[0m | \u001b[0m 0.2857  \u001b[0m | \u001b[0m 0.5233  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 40, 'colsample_bytree': 0.6458745308735936, 'subsample': 0.5363660778903093, 'max_depth': 11, 'reg_alpha': 0.07230715026359191, 'reg_lambda': 0.20257027817108597, 'min_split_gain': 0.08516021503858599, 'min_child_weight': 5.378024796866273, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.820173\tvalid_0's binary_logloss: 0.313625\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.820173\tvalid_0's binary_logloss: 0.313625\n",
      "best_iter: 100\n",
      "roc_auc: 0.8201732252579061\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8202  \u001b[0m | \u001b[0m 0.6459  \u001b[0m | \u001b[0m 10.66   \u001b[0m | \u001b[0m 5.378   \u001b[0m | \u001b[0m 0.08516 \u001b[0m | \u001b[0m 40.44   \u001b[0m | \u001b[0m 0.07231 \u001b[0m | \u001b[0m 0.2026  \u001b[0m | \u001b[0m 0.5364  \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 37, 'colsample_bytree': 1.0, 'subsample': 0.5, 'max_depth': 5, 'reg_alpha': 0.47976560671784996, 'reg_lambda': 0.4672166374269592, 'min_split_gain': 0.001, 'min_child_weight': 5.0, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.824399\tvalid_0's binary_logloss: 0.398498\n",
      "best_iter: 60\n",
      "roc_auc: 0.8243986852026369\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.8244  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 4.638   \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 0.001   \u001b[0m | \u001b[95m 37.19   \u001b[0m | \u001b[95m 0.4798  \u001b[0m | \u001b[95m 0.4672  \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 42, 'colsample_bytree': 1.0, 'subsample': 1.0, 'max_depth': 4, 'reg_alpha': 0.5, 'reg_lambda': 0.5, 'min_split_gain': 0.001, 'min_child_weight': 5.0, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.823908\tvalid_0's binary_logloss: 0.434022\n",
      "best_iter: 51\n",
      "roc_auc: 0.8239078658955834\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8239  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 42.01   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 30, 'colsample_bytree': 1.0, 'subsample': 0.5, 'max_depth': 4, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.019190753580395927, 'min_child_weight': 45.43173748163642, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.823188\tvalid_0's binary_logloss: 0.441471\n",
      "best_iter: 48\n",
      "roc_auc: 0.8231884450362008\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8232  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.039   \u001b[0m | \u001b[0m 45.43   \u001b[0m | \u001b[0m 0.01919 \u001b[0m | \u001b[0m 29.77   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 29, 'colsample_bytree': 0.6096261536747141, 'subsample': 0.5, 'max_depth': 12, 'reg_alpha': 0.0, 'reg_lambda': 0.4927283273348606, 'min_split_gain': 0.001, 'min_child_weight': 46.19470452482036, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.819537\tvalid_0's binary_logloss: 0.323785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.819537\tvalid_0's binary_logloss: 0.323785\n",
      "best_iter: 100\n",
      "roc_auc: 0.819537077021716\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.6096  \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 46.19   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 29.13   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.4927  \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 36, 'colsample_bytree': 1.0, 'subsample': 0.5, 'max_depth': 4, 'reg_alpha': 0.1584889870961066, 'reg_lambda': 0.07469274264424561, 'min_split_gain': 0.004050889923883039, 'min_child_weight': 49.790912594637206, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.822976\tvalid_0's binary_logloss: 0.368717\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[87]\tvalid_0's auc: 0.823184\tvalid_0's binary_logloss: 0.381556\n",
      "best_iter: 87\n",
      "roc_auc: 0.8231841790206684\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8232  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.0     \u001b[0m | \u001b[0m 49.79   \u001b[0m | \u001b[0m 0.004051\u001b[0m | \u001b[0m 35.67   \u001b[0m | \u001b[0m 0.1585  \u001b[0m | \u001b[0m 0.07469 \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 24, 'colsample_bytree': 1.0, 'subsample': 0.5, 'max_depth': 4, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.0754681112676826, 'min_child_weight': 39.15452432051268, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.822963\tvalid_0's binary_logloss: 0.368577\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[91]\tvalid_0's auc: 0.823308\tvalid_0's binary_logloss: 0.376936\n",
      "best_iter: 91\n",
      "roc_auc: 0.8233084053929718\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8233  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.0     \u001b[0m | \u001b[0m 39.15   \u001b[0m | \u001b[0m 0.07547 \u001b[0m | \u001b[0m 24.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "params: {'n_estimator': 200, 'learning_rate': 0.02, 'num_leaves': 24, 'colsample_bytree': 1.0, 'subsample': 0.5, 'max_depth': 4, 'reg_alpha': 0.5, 'reg_lambda': 0.5, 'min_split_gain': 0.001, 'min_child_weight': 50.0, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\tvalid_0's auc: 0.82266\tvalid_0's binary_logloss: 0.369184\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[89]\tvalid_0's auc: 0.822724\tvalid_0's binary_logloss: 0.38036\n",
      "best_iter: 89\n",
      "roc_auc: 0.8227242456660695\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8227  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 24.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "BO_lgb.maximize(init_points=5, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.8243986852026369,\n",
       " 'params': {'colsample_bytree': 1.0,\n",
       "  'max_depth': 4.637690794622835,\n",
       "  'min_child_weight': 5.0,\n",
       "  'min_split_gain': 0.001,\n",
       "  'num_leaves': 37.186594168843925,\n",
       "  'reg_alpha': 0.47976560671784996,\n",
       "  'reg_lambda': 0.4672166374269592,\n",
       "  'subsample': 0.5}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BO_lgb.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.810001\tvalid_0's binary_logloss: 0.681956\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.808409\tvalid_0's binary_logloss: 0.671286\n",
      "[3]\tvalid_0's auc: 0.81075\tvalid_0's binary_logloss: 0.661017\n",
      "[4]\tvalid_0's auc: 0.810779\tvalid_0's binary_logloss: 0.651084\n",
      "[5]\tvalid_0's auc: 0.810817\tvalid_0's binary_logloss: 0.641506\n",
      "[6]\tvalid_0's auc: 0.811211\tvalid_0's binary_logloss: 0.632338\n",
      "[7]\tvalid_0's auc: 0.812419\tvalid_0's binary_logloss: 0.623338\n",
      "[8]\tvalid_0's auc: 0.813642\tvalid_0's binary_logloss: 0.614693\n",
      "[9]\tvalid_0's auc: 0.814373\tvalid_0's binary_logloss: 0.606337\n",
      "[10]\tvalid_0's auc: 0.814181\tvalid_0's binary_logloss: 0.598242\n",
      "[11]\tvalid_0's auc: 0.814861\tvalid_0's binary_logloss: 0.590496\n",
      "[12]\tvalid_0's auc: 0.814851\tvalid_0's binary_logloss: 0.582938\n",
      "[13]\tvalid_0's auc: 0.815953\tvalid_0's binary_logloss: 0.575684\n",
      "[14]\tvalid_0's auc: 0.815874\tvalid_0's binary_logloss: 0.568659\n",
      "[15]\tvalid_0's auc: 0.816024\tvalid_0's binary_logloss: 0.561891\n",
      "[16]\tvalid_0's auc: 0.816042\tvalid_0's binary_logloss: 0.555304\n",
      "[17]\tvalid_0's auc: 0.816212\tvalid_0's binary_logloss: 0.549031\n",
      "[18]\tvalid_0's auc: 0.816562\tvalid_0's binary_logloss: 0.542877\n",
      "[19]\tvalid_0's auc: 0.816615\tvalid_0's binary_logloss: 0.536989\n",
      "[20]\tvalid_0's auc: 0.816987\tvalid_0's binary_logloss: 0.531209\n",
      "[21]\tvalid_0's auc: 0.817013\tvalid_0's binary_logloss: 0.525707\n",
      "[22]\tvalid_0's auc: 0.817142\tvalid_0's binary_logloss: 0.520314\n",
      "[23]\tvalid_0's auc: 0.817723\tvalid_0's binary_logloss: 0.515133\n",
      "[24]\tvalid_0's auc: 0.817687\tvalid_0's binary_logloss: 0.510095\n",
      "[25]\tvalid_0's auc: 0.817588\tvalid_0's binary_logloss: 0.505182\n",
      "[26]\tvalid_0's auc: 0.81772\tvalid_0's binary_logloss: 0.500493\n",
      "[27]\tvalid_0's auc: 0.81775\tvalid_0's binary_logloss: 0.495958\n",
      "[28]\tvalid_0's auc: 0.817508\tvalid_0's binary_logloss: 0.491458\n",
      "[29]\tvalid_0's auc: 0.817426\tvalid_0's binary_logloss: 0.487117\n",
      "[30]\tvalid_0's auc: 0.817413\tvalid_0's binary_logloss: 0.482985\n",
      "[31]\tvalid_0's auc: 0.818071\tvalid_0's binary_logloss: 0.479014\n",
      "[32]\tvalid_0's auc: 0.819516\tvalid_0's binary_logloss: 0.475086\n",
      "[33]\tvalid_0's auc: 0.819746\tvalid_0's binary_logloss: 0.471276\n",
      "[34]\tvalid_0's auc: 0.819925\tvalid_0's binary_logloss: 0.46766\n",
      "[35]\tvalid_0's auc: 0.820106\tvalid_0's binary_logloss: 0.463995\n",
      "[36]\tvalid_0's auc: 0.819978\tvalid_0's binary_logloss: 0.46042\n",
      "[37]\tvalid_0's auc: 0.820204\tvalid_0's binary_logloss: 0.457024\n",
      "[38]\tvalid_0's auc: 0.82077\tvalid_0's binary_logloss: 0.453782\n",
      "[39]\tvalid_0's auc: 0.821495\tvalid_0's binary_logloss: 0.45052\n",
      "[40]\tvalid_0's auc: 0.821746\tvalid_0's binary_logloss: 0.447446\n",
      "[41]\tvalid_0's auc: 0.822078\tvalid_0's binary_logloss: 0.44438\n",
      "[42]\tvalid_0's auc: 0.82257\tvalid_0's binary_logloss: 0.441419\n",
      "[43]\tvalid_0's auc: 0.822588\tvalid_0's binary_logloss: 0.438503\n",
      "[44]\tvalid_0's auc: 0.822804\tvalid_0's binary_logloss: 0.435622\n",
      "[45]\tvalid_0's auc: 0.822723\tvalid_0's binary_logloss: 0.43283\n",
      "[46]\tvalid_0's auc: 0.822943\tvalid_0's binary_logloss: 0.430043\n",
      "[47]\tvalid_0's auc: 0.823063\tvalid_0's binary_logloss: 0.427457\n",
      "[48]\tvalid_0's auc: 0.822865\tvalid_0's binary_logloss: 0.424832\n",
      "[49]\tvalid_0's auc: 0.823189\tvalid_0's binary_logloss: 0.422197\n",
      "[50]\tvalid_0's auc: 0.823131\tvalid_0's binary_logloss: 0.419779\n",
      "[51]\tvalid_0's auc: 0.823329\tvalid_0's binary_logloss: 0.417455\n",
      "[52]\tvalid_0's auc: 0.823438\tvalid_0's binary_logloss: 0.415104\n",
      "[53]\tvalid_0's auc: 0.823709\tvalid_0's binary_logloss: 0.412785\n",
      "[54]\tvalid_0's auc: 0.82381\tvalid_0's binary_logloss: 0.410678\n",
      "[55]\tvalid_0's auc: 0.823916\tvalid_0's binary_logloss: 0.408492\n",
      "[56]\tvalid_0's auc: 0.824071\tvalid_0's binary_logloss: 0.406404\n",
      "[57]\tvalid_0's auc: 0.824152\tvalid_0's binary_logloss: 0.404318\n",
      "[58]\tvalid_0's auc: 0.824175\tvalid_0's binary_logloss: 0.402324\n",
      "[59]\tvalid_0's auc: 0.824237\tvalid_0's binary_logloss: 0.400429\n",
      "[60]\tvalid_0's auc: 0.824399\tvalid_0's binary_logloss: 0.398498\n",
      "[61]\tvalid_0's auc: 0.824244\tvalid_0's binary_logloss: 0.396612\n",
      "[62]\tvalid_0's auc: 0.824217\tvalid_0's binary_logloss: 0.394859\n",
      "[63]\tvalid_0's auc: 0.824288\tvalid_0's binary_logloss: 0.393169\n",
      "[64]\tvalid_0's auc: 0.8241\tvalid_0's binary_logloss: 0.391389\n",
      "[65]\tvalid_0's auc: 0.823986\tvalid_0's binary_logloss: 0.389647\n",
      "[66]\tvalid_0's auc: 0.823941\tvalid_0's binary_logloss: 0.387975\n",
      "[67]\tvalid_0's auc: 0.823877\tvalid_0's binary_logloss: 0.386335\n",
      "[68]\tvalid_0's auc: 0.823694\tvalid_0's binary_logloss: 0.384733\n",
      "[69]\tvalid_0's auc: 0.823555\tvalid_0's binary_logloss: 0.383216\n",
      "[70]\tvalid_0's auc: 0.823613\tvalid_0's binary_logloss: 0.381715\n",
      "[71]\tvalid_0's auc: 0.823481\tvalid_0's binary_logloss: 0.380286\n",
      "[72]\tvalid_0's auc: 0.82341\tvalid_0's binary_logloss: 0.378935\n",
      "[73]\tvalid_0's auc: 0.823318\tvalid_0's binary_logloss: 0.377515\n",
      "[74]\tvalid_0's auc: 0.822986\tvalid_0's binary_logloss: 0.376182\n",
      "[75]\tvalid_0's auc: 0.823168\tvalid_0's binary_logloss: 0.374843\n",
      "[76]\tvalid_0's auc: 0.823172\tvalid_0's binary_logloss: 0.373547\n",
      "[77]\tvalid_0's auc: 0.823033\tvalid_0's binary_logloss: 0.372388\n",
      "[78]\tvalid_0's auc: 0.8233\tvalid_0's binary_logloss: 0.371083\n",
      "[79]\tvalid_0's auc: 0.823206\tvalid_0's binary_logloss: 0.369902\n",
      "[80]\tvalid_0's auc: 0.823034\tvalid_0's binary_logloss: 0.36876\n",
      "[81]\tvalid_0's auc: 0.823015\tvalid_0's binary_logloss: 0.367578\n",
      "[82]\tvalid_0's auc: 0.823093\tvalid_0's binary_logloss: 0.366396\n",
      "[83]\tvalid_0's auc: 0.822912\tvalid_0's binary_logloss: 0.365343\n",
      "[84]\tvalid_0's auc: 0.822705\tvalid_0's binary_logloss: 0.364252\n",
      "[85]\tvalid_0's auc: 0.822674\tvalid_0's binary_logloss: 0.363161\n",
      "[86]\tvalid_0's auc: 0.82297\tvalid_0's binary_logloss: 0.361947\n",
      "[87]\tvalid_0's auc: 0.823116\tvalid_0's binary_logloss: 0.360974\n",
      "[88]\tvalid_0's auc: 0.823323\tvalid_0's binary_logloss: 0.359818\n",
      "[89]\tvalid_0's auc: 0.823297\tvalid_0's binary_logloss: 0.35884\n",
      "[90]\tvalid_0's auc: 0.823169\tvalid_0's binary_logloss: 0.357982\n",
      "[91]\tvalid_0's auc: 0.823192\tvalid_0's binary_logloss: 0.356984\n",
      "[92]\tvalid_0's auc: 0.823346\tvalid_0's binary_logloss: 0.356098\n",
      "[93]\tvalid_0's auc: 0.823266\tvalid_0's binary_logloss: 0.35528\n",
      "[94]\tvalid_0's auc: 0.823397\tvalid_0's binary_logloss: 0.354441\n",
      "[95]\tvalid_0's auc: 0.823288\tvalid_0's binary_logloss: 0.353514\n",
      "[96]\tvalid_0's auc: 0.823278\tvalid_0's binary_logloss: 0.352789\n",
      "[97]\tvalid_0's auc: 0.823194\tvalid_0's binary_logloss: 0.351898\n",
      "[98]\tvalid_0's auc: 0.823134\tvalid_0's binary_logloss: 0.350952\n",
      "[99]\tvalid_0's auc: 0.822934\tvalid_0's binary_logloss: 0.350116\n",
      "[100]\tvalid_0's auc: 0.822866\tvalid_0's binary_logloss: 0.349377\n",
      "[101]\tvalid_0's auc: 0.822824\tvalid_0's binary_logloss: 0.348586\n",
      "[102]\tvalid_0's auc: 0.82267\tvalid_0's binary_logloss: 0.347782\n",
      "[103]\tvalid_0's auc: 0.822831\tvalid_0's binary_logloss: 0.347158\n",
      "[104]\tvalid_0's auc: 0.822831\tvalid_0's binary_logloss: 0.346427\n",
      "[105]\tvalid_0's auc: 0.822697\tvalid_0's binary_logloss: 0.345527\n",
      "[106]\tvalid_0's auc: 0.822637\tvalid_0's binary_logloss: 0.344806\n",
      "[107]\tvalid_0's auc: 0.822621\tvalid_0's binary_logloss: 0.344138\n",
      "[108]\tvalid_0's auc: 0.82257\tvalid_0's binary_logloss: 0.343511\n",
      "[109]\tvalid_0's auc: 0.822663\tvalid_0's binary_logloss: 0.342776\n",
      "[110]\tvalid_0's auc: 0.822609\tvalid_0's binary_logloss: 0.342134\n",
      "[111]\tvalid_0's auc: 0.822612\tvalid_0's binary_logloss: 0.341399\n",
      "[112]\tvalid_0's auc: 0.822746\tvalid_0's binary_logloss: 0.340848\n",
      "[113]\tvalid_0's auc: 0.822619\tvalid_0's binary_logloss: 0.34027\n",
      "[114]\tvalid_0's auc: 0.82356\tvalid_0's binary_logloss: 0.339522\n",
      "[115]\tvalid_0's auc: 0.823446\tvalid_0's binary_logloss: 0.338878\n",
      "[116]\tvalid_0's auc: 0.823503\tvalid_0's binary_logloss: 0.338167\n",
      "[117]\tvalid_0's auc: 0.823581\tvalid_0's binary_logloss: 0.337519\n",
      "[118]\tvalid_0's auc: 0.823603\tvalid_0's binary_logloss: 0.337032\n",
      "[119]\tvalid_0's auc: 0.82381\tvalid_0's binary_logloss: 0.336464\n",
      "[120]\tvalid_0's auc: 0.823742\tvalid_0's binary_logloss: 0.336003\n",
      "[121]\tvalid_0's auc: 0.823924\tvalid_0's binary_logloss: 0.33529\n",
      "[122]\tvalid_0's auc: 0.823868\tvalid_0's binary_logloss: 0.334874\n",
      "[123]\tvalid_0's auc: 0.823954\tvalid_0's binary_logloss: 0.334126\n",
      "[124]\tvalid_0's auc: 0.824069\tvalid_0's binary_logloss: 0.333448\n",
      "[125]\tvalid_0's auc: 0.824085\tvalid_0's binary_logloss: 0.332983\n",
      "[126]\tvalid_0's auc: 0.824235\tvalid_0's binary_logloss: 0.332271\n",
      "[127]\tvalid_0's auc: 0.824343\tvalid_0's binary_logloss: 0.331636\n",
      "[128]\tvalid_0's auc: 0.824325\tvalid_0's binary_logloss: 0.331191\n",
      "[129]\tvalid_0's auc: 0.824341\tvalid_0's binary_logloss: 0.330497\n",
      "[130]\tvalid_0's auc: 0.824397\tvalid_0's binary_logloss: 0.329893\n",
      "[131]\tvalid_0's auc: 0.824462\tvalid_0's binary_logloss: 0.329242\n",
      "[132]\tvalid_0's auc: 0.824377\tvalid_0's binary_logloss: 0.328924\n",
      "[133]\tvalid_0's auc: 0.824466\tvalid_0's binary_logloss: 0.328345\n",
      "[134]\tvalid_0's auc: 0.824553\tvalid_0's binary_logloss: 0.327911\n",
      "[135]\tvalid_0's auc: 0.824381\tvalid_0's binary_logloss: 0.327385\n",
      "[136]\tvalid_0's auc: 0.824277\tvalid_0's binary_logloss: 0.326957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137]\tvalid_0's auc: 0.82427\tvalid_0's binary_logloss: 0.326454\n",
      "[138]\tvalid_0's auc: 0.824198\tvalid_0's binary_logloss: 0.326138\n",
      "[139]\tvalid_0's auc: 0.824281\tvalid_0's binary_logloss: 0.325746\n",
      "[140]\tvalid_0's auc: 0.824247\tvalid_0's binary_logloss: 0.325223\n",
      "[141]\tvalid_0's auc: 0.824219\tvalid_0's binary_logloss: 0.324766\n",
      "[142]\tvalid_0's auc: 0.824107\tvalid_0's binary_logloss: 0.324453\n",
      "[143]\tvalid_0's auc: 0.824123\tvalid_0's binary_logloss: 0.323954\n",
      "[144]\tvalid_0's auc: 0.824052\tvalid_0's binary_logloss: 0.323671\n",
      "[145]\tvalid_0's auc: 0.824078\tvalid_0's binary_logloss: 0.323202\n",
      "[146]\tvalid_0's auc: 0.824005\tvalid_0's binary_logloss: 0.322735\n",
      "[147]\tvalid_0's auc: 0.823922\tvalid_0's binary_logloss: 0.322454\n",
      "[148]\tvalid_0's auc: 0.824031\tvalid_0's binary_logloss: 0.321991\n",
      "[149]\tvalid_0's auc: 0.824105\tvalid_0's binary_logloss: 0.321548\n",
      "[150]\tvalid_0's auc: 0.824026\tvalid_0's binary_logloss: 0.321276\n",
      "[151]\tvalid_0's auc: 0.824097\tvalid_0's binary_logloss: 0.320845\n",
      "[152]\tvalid_0's auc: 0.824144\tvalid_0's binary_logloss: 0.320416\n",
      "[153]\tvalid_0's auc: 0.824274\tvalid_0's binary_logloss: 0.319834\n",
      "[154]\tvalid_0's auc: 0.824287\tvalid_0's binary_logloss: 0.319426\n",
      "[155]\tvalid_0's auc: 0.824244\tvalid_0's binary_logloss: 0.319028\n",
      "[156]\tvalid_0's auc: 0.824423\tvalid_0's binary_logloss: 0.318577\n",
      "[157]\tvalid_0's auc: 0.824532\tvalid_0's binary_logloss: 0.318041\n",
      "[158]\tvalid_0's auc: 0.824465\tvalid_0's binary_logloss: 0.317663\n",
      "[159]\tvalid_0's auc: 0.824295\tvalid_0's binary_logloss: 0.31745\n",
      "[160]\tvalid_0's auc: 0.824161\tvalid_0's binary_logloss: 0.317072\n",
      "[161]\tvalid_0's auc: 0.824337\tvalid_0's binary_logloss: 0.316612\n",
      "[162]\tvalid_0's auc: 0.824102\tvalid_0's binary_logloss: 0.316058\n",
      "[163]\tvalid_0's auc: 0.824134\tvalid_0's binary_logloss: 0.315518\n",
      "[164]\tvalid_0's auc: 0.82406\tvalid_0's binary_logloss: 0.315276\n",
      "[165]\tvalid_0's auc: 0.823996\tvalid_0's binary_logloss: 0.314907\n",
      "[166]\tvalid_0's auc: 0.824079\tvalid_0's binary_logloss: 0.314382\n",
      "[167]\tvalid_0's auc: 0.824093\tvalid_0's binary_logloss: 0.314142\n",
      "[168]\tvalid_0's auc: 0.823957\tvalid_0's binary_logloss: 0.313936\n",
      "[169]\tvalid_0's auc: 0.824031\tvalid_0's binary_logloss: 0.31319\n",
      "[170]\tvalid_0's auc: 0.823882\tvalid_0's binary_logloss: 0.312911\n",
      "[171]\tvalid_0's auc: 0.823863\tvalid_0's binary_logloss: 0.312696\n",
      "[172]\tvalid_0's auc: 0.823724\tvalid_0's binary_logloss: 0.312252\n",
      "[173]\tvalid_0's auc: 0.823747\tvalid_0's binary_logloss: 0.311927\n",
      "[174]\tvalid_0's auc: 0.823647\tvalid_0's binary_logloss: 0.31165\n",
      "[175]\tvalid_0's auc: 0.823619\tvalid_0's binary_logloss: 0.310908\n",
      "[176]\tvalid_0's auc: 0.82348\tvalid_0's binary_logloss: 0.31076\n",
      "[177]\tvalid_0's auc: 0.823566\tvalid_0's binary_logloss: 0.310357\n",
      "[178]\tvalid_0's auc: 0.823522\tvalid_0's binary_logloss: 0.309899\n",
      "[179]\tvalid_0's auc: 0.823548\tvalid_0's binary_logloss: 0.30972\n",
      "[180]\tvalid_0's auc: 0.823533\tvalid_0's binary_logloss: 0.309034\n",
      "[181]\tvalid_0's auc: 0.823501\tvalid_0's binary_logloss: 0.308768\n",
      "[182]\tvalid_0's auc: 0.823422\tvalid_0's binary_logloss: 0.308472\n",
      "[183]\tvalid_0's auc: 0.823451\tvalid_0's binary_logloss: 0.307946\n",
      "[184]\tvalid_0's auc: 0.823429\tvalid_0's binary_logloss: 0.30769\n",
      "[185]\tvalid_0's auc: 0.823411\tvalid_0's binary_logloss: 0.307352\n",
      "[186]\tvalid_0's auc: 0.82339\tvalid_0's binary_logloss: 0.307038\n",
      "[187]\tvalid_0's auc: 0.823388\tvalid_0's binary_logloss: 0.306425\n",
      "[188]\tvalid_0's auc: 0.823237\tvalid_0's binary_logloss: 0.305924\n",
      "[189]\tvalid_0's auc: 0.823156\tvalid_0's binary_logloss: 0.305658\n",
      "[190]\tvalid_0's auc: 0.823049\tvalid_0's binary_logloss: 0.305135\n",
      "[191]\tvalid_0's auc: 0.823205\tvalid_0's binary_logloss: 0.304602\n",
      "[192]\tvalid_0's auc: 0.822896\tvalid_0's binary_logloss: 0.303955\n",
      "[193]\tvalid_0's auc: 0.822918\tvalid_0's binary_logloss: 0.303673\n",
      "[194]\tvalid_0's auc: 0.8229\tvalid_0's binary_logloss: 0.303405\n",
      "[195]\tvalid_0's auc: 0.8229\tvalid_0's binary_logloss: 0.302896\n",
      "[196]\tvalid_0's auc: 0.822797\tvalid_0's binary_logloss: 0.302732\n",
      "[197]\tvalid_0's auc: 0.822746\tvalid_0's binary_logloss: 0.302134\n",
      "[198]\tvalid_0's auc: 0.822724\tvalid_0's binary_logloss: 0.301594\n",
      "[199]\tvalid_0's auc: 0.822654\tvalid_0's binary_logloss: 0.301366\n",
      "[200]\tvalid_0's auc: 0.822547\tvalid_0's binary_logloss: 0.301216\n",
      "[201]\tvalid_0's auc: 0.822567\tvalid_0's binary_logloss: 0.300643\n",
      "[202]\tvalid_0's auc: 0.82248\tvalid_0's binary_logloss: 0.300342\n",
      "[203]\tvalid_0's auc: 0.822517\tvalid_0's binary_logloss: 0.299846\n",
      "[204]\tvalid_0's auc: 0.822381\tvalid_0's binary_logloss: 0.299657\n",
      "[205]\tvalid_0's auc: 0.822395\tvalid_0's binary_logloss: 0.299103\n",
      "[206]\tvalid_0's auc: 0.822387\tvalid_0's binary_logloss: 0.298566\n",
      "[207]\tvalid_0's auc: 0.822324\tvalid_0's binary_logloss: 0.298128\n",
      "[208]\tvalid_0's auc: 0.822258\tvalid_0's binary_logloss: 0.298005\n",
      "[209]\tvalid_0's auc: 0.82222\tvalid_0's binary_logloss: 0.297782\n",
      "[210]\tvalid_0's auc: 0.822203\tvalid_0's binary_logloss: 0.297595\n",
      "[211]\tvalid_0's auc: 0.822128\tvalid_0's binary_logloss: 0.297273\n",
      "[212]\tvalid_0's auc: 0.822147\tvalid_0's binary_logloss: 0.296695\n",
      "[213]\tvalid_0's auc: 0.822056\tvalid_0's binary_logloss: 0.296274\n",
      "[214]\tvalid_0's auc: 0.822041\tvalid_0's binary_logloss: 0.295847\n",
      "[215]\tvalid_0's auc: 0.82191\tvalid_0's binary_logloss: 0.295629\n",
      "[216]\tvalid_0's auc: 0.821943\tvalid_0's binary_logloss: 0.295164\n",
      "[217]\tvalid_0's auc: 0.821879\tvalid_0's binary_logloss: 0.294788\n",
      "[218]\tvalid_0's auc: 0.821491\tvalid_0's binary_logloss: 0.294497\n",
      "[219]\tvalid_0's auc: 0.821477\tvalid_0's binary_logloss: 0.294368\n",
      "[220]\tvalid_0's auc: 0.821466\tvalid_0's binary_logloss: 0.293991\n",
      "[221]\tvalid_0's auc: 0.821426\tvalid_0's binary_logloss: 0.293623\n",
      "[222]\tvalid_0's auc: 0.821227\tvalid_0's binary_logloss: 0.293531\n",
      "[223]\tvalid_0's auc: 0.82123\tvalid_0's binary_logloss: 0.293372\n",
      "[224]\tvalid_0's auc: 0.821118\tvalid_0's binary_logloss: 0.292909\n",
      "[225]\tvalid_0's auc: 0.821112\tvalid_0's binary_logloss: 0.292771\n",
      "[226]\tvalid_0's auc: 0.821103\tvalid_0's binary_logloss: 0.292413\n",
      "[227]\tvalid_0's auc: 0.821155\tvalid_0's binary_logloss: 0.291901\n",
      "[228]\tvalid_0's auc: 0.82114\tvalid_0's binary_logloss: 0.29175\n",
      "[229]\tvalid_0's auc: 0.821036\tvalid_0's binary_logloss: 0.291481\n",
      "[230]\tvalid_0's auc: 0.821005\tvalid_0's binary_logloss: 0.291153\n",
      "[231]\tvalid_0's auc: 0.821002\tvalid_0's binary_logloss: 0.290809\n",
      "[232]\tvalid_0's auc: 0.820917\tvalid_0's binary_logloss: 0.290523\n",
      "[233]\tvalid_0's auc: 0.820873\tvalid_0's binary_logloss: 0.290197\n",
      "[234]\tvalid_0's auc: 0.820849\tvalid_0's binary_logloss: 0.289768\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.824553\tvalid_0's binary_logloss: 0.327911\n",
      "ROC AUC: 0.8246\n"
     ]
    }
   ],
   "source": [
    "max_params = BO_lgb.max['params']\n",
    "\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "\n",
    "lgbm_clf_bayes_best = LGBMClassifier(n_estimators=1000, learning_rate=0.02, **max_params)\n",
    "\n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_clf_bayes_best.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"auc\", eval_set=evals,\n",
    "                verbose=True)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf_bayes_best.predict_proba(X_test)[:,1],average='macro')\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.02, max_depth=5, min_child_weight=5.0,\n",
       "               min_split_gain=0.001, n_estimators=1000, num_leaves=37,\n",
       "               reg_alpha=0.47976560671784996, reg_lambda=0.4672166374269592,\n",
       "               subsample=0.5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf_bayes_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.02, max_depth=5, min_child_weight=5.0,\n",
       "               min_split_gain=0.001, n_estimators=1000, num_leaves=37,\n",
       "               reg_alpha=0.47976560671784996, reg_lambda=0.4672166374269592,\n",
       "               subsample=0.5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf_bayes_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape : (15204, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.15903079 0.84096921]\n",
      " [0.99429056 0.00570944]\n",
      " [0.11125579 0.88874421]]\n",
      "두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.15903079 0.84096921 0.15903079 0.84096921]\n",
      " [0.99429056 0.00570944 0.99429056 0.00570944]\n",
      " [0.11125579 0.88874421 0.11125579 0.88874421]]\n"
     ]
    }
   ],
   "source": [
    "## 1 ##\n",
    "\n",
    "pred_proba = lgbm_clf_bayes_best.predict_proba(X_test) ##\n",
    "pred  = lgbm_clf_bayes_best.predict_proba(X_test) ##\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,2)],axis=1)\n",
    "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[13479  1123]\n",
      " [  363   239]]\n",
      "정확도: 0.9023, 정밀도: 0.1755, 재현율: 0.3970, F1_score:  0.397010, ROC_AUC_Score:  0.243381\n"
     ]
    }
   ],
   "source": [
    "## 2\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Binarizer의 threshold 설정값. 분류 결정 임곗값임.  \n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba( ) 반환값의 두번째 컬럼 , 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lgbm_clf_bayes_best.predict_proba(X_test)[:, 1] ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFzCAYAAAA5aKBnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3wU1f7/8dfJplcCgVBCk957B2lKUQQLiliuWK4V9drb9dqu92v/2bsCVmyo2LGABaUK0nsNvYb0en5/TIgBkrBANrObvJ+Pxzym7uSdpXx2Zs+cY6y1iIiISOUV5HYAERER8S0VexERkUpOxV5ERKSSU7EXERGp5FTsRUREKjkVexERkUou2O0AxyohIcE2atSI9PR0oqKi3I7jtUDLC4GXWXl9L9AyK6/vBVrmQM07f/783dbamsd9ImttQE1dunSx1lo7ffp0G0gCLa+1gZdZeX0v0DIrr+8FWuZAzQvMsydQO3UbX0REpJJTsRcREankVOxFREQquYBroCciIv4pNzeX5ORksrKy3I5Sqri4OJYvX+52jFKFh4eTlJRESEhIuZ5XxV5ERMpFcnIyMTExNGrUCGOM23FKlJqaSkxMjNsxSmStZc+ePSQnJ9O4ceNyPbdu44uISLnIysqiRo0aflvo/Z0xhho1avjkzoiKvYiIlBsV+hPjq/dPxV5ERKQM8+bN44Ybbih1/9atWxk9enQFJjp2+s5eRESqlPz8fDwej9fHd+3ala5du5a6v27dunz88cflEc1nfHZlb4x50xiz0xizpJT9xhjzrDFmjTFmkTGms6+yiIhI1bBhwwZatmzJJZdcQvv27Rk9ejQZGRk0atSIBx98kCFDhvDRRx8xbdo0evXqRefOnTn33HNJS0sDYO7cufTu3ZsOHTrQvXt3UlNTmTFjBiNGjADg559/pmPHjnTs2JFOnTqRmprKhg0baNu2LeC0W7j00ktp164dnTp1Yvr06QBMnDiRs88+m2HDhtGsWTNuv/32Cn1ffHllPxF4HnirlP3DgWaFUw/gpcK5iIhUAmNe+eOIbSPa1+HiXo3IzMln3IQ5R+wf3SWJc7vWZ296Dte8M/+QfR9c1curn7ty5UreeOMN+vTpw2WXXcaLL74IOI+1TZs2jezsbM4++2x++OEHoqKiePTRR3nqqae48847GTNmDB988AHdunXjwIEDREREHHLuJ554ghdeeIE+ffqQlpZGeHj4IftfeOEFABYvXsyKFSsYMmQIq1atAmDhwoUsWLCAsLAwWrRowfXXX0/9+vW9+p1OlM+u7K21vwB7yzhkFPBWYfe/s4Bqxpg6vspToqwUWPEVZKdV6I8VERHfqV+/Pn369AHgoosu4rfffgNgzJgxAMyaNYtly5bRp08fOnbsyKRJk9i4cSMrV66kTp06dOvWDYDY2FiCgw+9Ju7Tpw8333wzzz77LPv37z9i/2+//cbFF18MQMuWLWnYsGFRsR88eDBxcXGEh4fTunVrNm7c6Ls34TBufmdfD9hcbD25cNu2ww80xlwJXAmQmJjIjBkzSEtLY8aMGScUIH7vAjosup+MiDrM6/osBZ7QEzpfWcojb0ULtMzK63uBlll5fa945ri4OFJTU4v2vX5B2xJfc/CYsvaHlLC/+LnLylP82IyMDPLz84sGhMnPzycjI4MBAwYwYcKEQ167ZMkSCgoKjvg5GRkZ5OXlkZqaynXXXceAAQOYNm0aPXr0YOrUqYSFhRW9Ljc3l4yMjKJz5Ofnk56eTlZWFsaYou3WWg4cOFDi75SVlVX0npbX3wk3i31JzxfYkg601r4KvArQtWtXO2DAAGbMmMGAAQNOLEFuT9j4BpEpmzm5dga0GXJi5ytDueStYIGWWXl9L9AyK6/vFc+8fPly1zusiY6OZvPmzSxZsoRevXrx+eefM2DAABYvXkx0dDQej4eBAwdy6623smPHDpo2bUpGRgbJycl06dKFHTt2sGLFCrp160ZqaioRERFERkYSHBxMTEwMa9eupWfPnvTs2ZM///yTzZs307FjR4KCgoiJiWHQoEF8+umnjBgxglWrVrFlyxY6d+7MypUrCQ0NLXp/goODiYyMLPH9Cg8Pp1OnTkD5/Z1w89G7ZKD4lxVJwNYKTRASDuO+cpZ3LqvQHy0iIr7RqlUrJk2aRPv27dm7dy/XXHPNIftr1qzJxIkTGTt2LO3bt6dnz56sWLGC0NBQPvjgA66//no6dOjAqaeeekQHN08//TRt27alQ4cOREREMHz48EP2X3vtteTn59OuXTvGjBnDxIkTCQsL8/nvfDRuXtlPBcYbYybjNMxLsdYecQvf56o1cOY/Pwr974Ag7x/HEBER/xMUFMTLL798yLYNGzYAf9/eHzRoEHPnzj3itd26dWPWrFmHbBswYEDR1fVzzz13xGsaNWrEkiXOg2fh4eFMnDjxiGPGjRvHuHHjita//PJLb3+dcuHLR+/eB/4AWhhjko0xlxtjrjbGXF14yNfAOmAN8Bpwra+yHCUoNChs4bl7lSsRREREfMlnV/bW2rFH2W+B63z184/JgLvgrZGwZw3UauV2GhEROU7Fr7Llb+ouFyCm8Im/+ZPczSEiIuIDKvYACc2c+ZrvIX23u1lERETKmYo9ON/bD/2fs7xkirtZREREypmK/UFdxjnzb26D/FxXo4iIiJQnFfuDQqOgWWGnOsu/cDeLiIj4jYkTJzJ+/HgA7r//fp544gmXEx07FfviznzJmf+phnoiIoHOWktBQYHbMfyCin1xUQkQEgXrZkBBvttpRETkGG3YsIFWrVpx7bXX0rlzZx566CG6detG+/btue+++4qOe+utt2jfvj0dOnQoGrjmiy++oEePHnTq1IlTTjmFHTt2uPVrlDs3e9DzT50ugjmvQOo2iEtyO42ISGD65k7Yvrh8z1m7HQx/5KiHrVy5kgkTJnDmmWfy8ccfM2fOHKy1jBw5kpkzZ1K/fn0efvhhZs6cSUJCAnv3OgO09u3bl1mzZmGM4fXXX+exxx7jySefLN/fwSUq9odr0MMp9ss+h17+0eePiIh4r2HDhvTs2ZNbb72VadOmFQ0qk5aWxtq1a1m9ejWjR48mISEBgOrVqwOQnJzMmDFj2LZtGzk5OTRu3Ni136G8qdgfrsXpzvzPt1TsRUSOlxdX4L4SFRUFON/Z33XXXVx11VVF+1JTU5kwYQLGHDnw6vXXX8/NN9/MyJEjmTFjBvfff39FRfY5fWd/uJBwqH4S7FrhdhIRETkBQ4cO5c033ywa437Lli3s2rWLwYMH8+GHH7Jnzx6Aotv4KSkp1KtXD4BJkypXQ21d2ZekYW/Yuw6S50NSF7fTiIjIcRgyZAjLly+nVy9nsLPo6GhefvllOnTowD333EP//v3xeDx06tSJiRMncv/993PuuedSr149evbsyfr1613+DcqPin1JelwNC96Br26Cq35xO42IiHjp8IFwbrzxRm688cai9YND3F5yySVccsklh7x21KhRjBo16ohzFh+eNlBv7es2fklqt3Pm2/5yN4eIiEg5ULEvTffCBh0/PuhuDhERkROkYl+aHoXF/tcnwVp3s4iIiJwAFfvS1GgCQx52lrcvcjeLiEiAsLo4OiG+ev9U7MtSr7MznzfB3RwiIgEgPDycPXv2qOAfJ2ste/bsITw8vNzPrdb4ZUnq5syXfgpnPO1uFhERP5eUlERycjK7du1yO0qpsrKyfFJMy0t4eDhJSeXfVbuKfVk8IdD6TFj2mdOjXud/uJ1IRMRvhYSE+H0XszNmzCjqPrcq0W38ozn1AWe+4F13c4iIiBwnFfujiW8EtdvD5llqlS8iIgFJxd4biW2c+aIP3M0hIiJyHFTsvXHwEbyF77mbQ0RE5Dio2HsjqgYEh8OW+W4nEREROWYq9t5qPhRy0mBv5RkFSUREqgYVe291vMiZP9sRDmx1N4uIiMgxULH3VtNToHF/Z/mjS93NIiIicgxU7L0VFASXTIWQKOcxvNwstxOJiIh4RcX+WPW72ZnPesHdHCIiIl5SsT9WvcY78w2/uZtDRETESyr2xyokHBJawNqf9CieiIgEBBX749HvFmf+2iDITnM3i4iIyFGo2B+PDmOgQW9neep4d7OIiIgchYr98bpkqjNf+qmeuxcREb+mYn+8PCFwxrPO8vvnu5tFRESkDCr2J6LzPyAsFnaucDuJiIhIqVTsT4Qx0Gok5GdD5j6304iIiJRIxf5ENR/qzN/TrXwREfFPKvYnqvVIZ755FuTnuptFRESkBCr25WHYI85840x3c4iIiJRAxb48NBvizN8aBXnZ7mYRERE5jIp9eajRBGq1dpbX/OhuFhERkcOo2JeXiz5x5pPHQkqyu1lERESKUbEvLzF1oM3ZzvIvj7ubRUREpBgV+/JiDJzzurM8fyL8+qSrcURERA5SsS9PQR44/31n+ccHYePv7uYRERFBxb78tTwNrvzZWd6+xN0sIiIiqNj7Ru12zvyb2yA3090sIiJS5anY+0KQB6o3cZYfrg1/vuVuHhERqdJ8WuyNMcOMMSuNMWuMMXeWsD/OGPOFMeYvY8xSY8ylvsxTocbPhSEPO8vzJ7mbRUREqjSfFXtjjAd4ARgOtAbGGmNaH3bYdcAya20HYADwpDEm1FeZKlSQB3qPh3pdYOsCTIH6zRcREXf48sq+O7DGWrvOWpsDTAZGHXaMBWKMMQaIBvYCeT7MVPFqtwebT5+Zl0BulttpRESkCvJlsa8HbC62nly4rbjngVbAVmAxcKO1tsCHmSrewHug2z8Jzk+HL29yO42IiFRBxlrrmxMbcy4w1Fp7ReH6xUB3a+31xY4ZDfQBbgaaAN8DHay1Bw4715XAlQCJiYldJk+eTFpaGtHR0T7JXt5MQR79fzkHgBkDPnc5jfcC6T0G5a0IgZZZeX0v0DIHat6BAwfOt9Z2Pe4TWWt9MgG9gO+Krd8F3HXYMV8B/Yqt/4TzgaDU83bp0sVaa+306dNtINn86lhr74u19s+33Y7itUB7j5XX9wIts/L6XqBlDtS8wDx7AjXZl7fx5wLNjDGNCxvdnQ9MPeyYTcBgAGNMItACWOfDTK7ZUm+Es/D5de4GERGRKsdnxd5amweMB74DlgMfWmuXGmOuNsZcXXjYQ0BvY8xi4EfgDmvtbl9lclNmZF3oMNZZ0ah4IiJSgYJ9eXJr7dfA14dte7nY8lZgiC8z+JXmw+Cv9+GZjnDvLmfwHBERER9TD3oVqeUIiGsABbmw8D2304iISBWhYl+RPMFw9a/O8pxX3c0iIiJVhop9RYuoBhHxsG0hZO5zO42IiFQBKvZuGHiPM3+0Eaz72dUoIiJS+anYu6HbFdDhAmf5rZGw8Xd384iISKWmYu8GY+Csl+DMwgcTJgyHfA2UIyIivqFi76aOY+Gkgc6yWueLiIiPqNi77fx3nfmsl9zNISIilZaKvdtCoyC2HuxaDl/dAj4amEhERKouFXt/MPI5Zz73dXi1PxRUrlF+RUTEXSr2/qDpYLhjg7O87S9I3+VqHBERqVxU7P1FRDyMecdZXvO9u1lERKRSUbH3Jw37OPMfH3Q3h4iIVCoq9v4ksjrUaAppO+CvyW6nERGRSkLF3t9c/Kkz//Qq2LXS3SwiIlIpqNj7m2oNYNC9zvLij9zNIiIilYKKvT/qd4sz1yA5IiJSDlTs/ZExULsdJM/RrXwRETlhKvb+6uDV/QvdYcE76llPRESOm4q9v2pzFnT+h7P8+XUw8xl384iISMA6arE3xkQaY+41xrxWuN7MGDPC99GEkc/BLYW38X+4D17spa50RUTkmHlzZT8ByAZ6Fa4nA//1WSI5VExtOP89CImEncvgwXjYsdTtVCIiEkC8KfZNrLWPAbkA1tpMwPg0lRyq5elwx0bofYOzvuAdd/OIiEhA8abY5xhjIgALYIxpgnOlLxUpOBSGPOQsq3c9ERE5Bt4U+/uAb4H6xph3gR+B232aSkqX2BYy98IidbgjIiLeOWqxt9Z+D5wNjAPeB7paa2f4NpaU6oIPnPmUK2Dj7+5mERGRgOBNa/yTgTZAKnAAaF24TdwQlwSdLnKW3z7L3SwiIhIQgr045rZiy+FAd2A+MMgnieToRr0A6bth1beQnQphMW4nEhERP3bUYm+tPaP4ujGmPvCYzxKJd5qd6hT73EwVexERKdPx9KCXDLQt7yByjEIinXluhrs5RETE7x31yt4Y8xyFj93hfDjoCPzly1DiheBwZz7vTRh8HwR53M0jIiJ+y5vv7OcVW84D3rfWzvRRHvFWo37OfOYzsGwqXD9fBV9ERErkzXf2kyoiiByj6Jrwz5/g9VNh33p4fyyMnQxBGttIREQOVWplMMYsNsYsKmFabIxZVJEhpRT1ujgD5UQnwurv4IvrIWOv26lERMTPlHVlr5HtAkF0TbjmD3iqpdNn/oJ34OzXoPWZThe7IiJS5ZV6ZW+t3VjWVJEh5SiiasB1s2HQv531Kf+E9893N5OIiPgNb3rQ62mMmWuMSTPG5Bhj8o0xByoinByD6ifBybfBVb9Ag16w9kf45XEoyHc7mYiIuMyb1lzPA2OB1UAEcAXwnC9DyQmo0wFGFv7x/PRfeLA6zHgUrC37dSIiUml51XTbWrsG8Fhr8621E4CBvo0lJyShGVw3B+p2dtZn/A8Wa5Q8EZGqypvn7DOMMaHAQmPMY8A2IMq3seSE1WwBV06HtJ3wRDPne/y0ndDzGj2PLyJSxXhzZX9x4XHjgXSgPnCOL0NJOYquBd2ucJan3QPf3eNuHhERqXDeFPvOgLXWHrDWPmCtvbnwtr4EitOfhJuWOsuzX3I3i4iIVDhviv1IYJUx5m1jzOnGGG9u/Yu/iUuCZkOd5TeHw1tnwh8vqLW+iEgVcNRib629FGgKfARcAKw1xrzu62DiA4PvhYZ9webDuunw3d3wfDdY/wvsWuV2OhER8RGvrtKttbnGmG9wRr+LAEbhPIIngaR2O7j0K2c5dQe83Af2roVJZ4AnFMa848zj6kNCU3eziohIufFmiNthwPk4j9vNAF4HzvNtLPG5mES4eQVsmQ87l8KXN8F7xf5Ya7enXnR32H8SVGvgXk4RETlh3lzZjwMmA1dZa7N9G0cqlCcYGvSA+t2dQXVyMiAnHRa8Dcs+oxmLYNKPTgO/Rn0hOMztxCIichy8GeJWnaxXdsY4Pe8d1OwU2LeRTVPup8HmKfDO2c7V/bBHnePi6rmXVUREjpla1kvJ4huyvvFFNDjtX/DOObB/E0we6+xLbAcxtaHzPyCpK8TWdTeriIiUScVeSmWDPM6V/E1LYdcKWP8rbPwdkufAjsWw5nvnwDNfhsQ2UKe9u4FFRKREKvZydMFhTtGv0wF6j3eezd+9Cn57GhZNhs+uhvA4uGOj85WAiIj4lVKfszfGLDbGLCphWmyMWeTNyY0xw4wxK40xa4wxd5ZyzABjzEJjzFJjzM/H+4tIBQryQK1WcNbLcMMC6H8HZKXAn5M0up6IiB8q68p+xImc2BjjAV4ATgWSgbnGmKnW2mXFjqkGvAgMs9ZuMsbUOpGfKRXMGKh+EjQ9FX5+FL64ERa+D5d/53YyEREpptRib63deILn7g6ssdauAzDGTMbpjGdZsWMuAKZYazcV/sydJ/gzxQ31u8ENC+GV/rB5FuzbAPGN3E4lIiKFjC3ltqsxJhWnx7wjduEMjBNb5omNGY1zxX5F4frFQA9r7fhixzwNhABtgBjgGWvtWyWc60rgSoDExMQukydPJi0tjejoaC9+Rf8QaHnh2DPHpiyn84I72R/XloWdHvZhspIF2nscaHkh8DIrr+8FWuZAzTtw4MD51tqux30ia61PJuBc4PVi6xcDzx12zPPALCAKSABWA83LOm+XLl2stdZOnz7dBpJAy2vtcWb+6WFr74u19qFEa5d/We6ZyhJo73Gg5bU28DIrr+8FWuZAzQvMsydQk71ujV/4fXp4sQ8Jm47ykmSgfrH1JGBrCcfsttamA+nGmF+ADoBGZQlUPa+BTX84g+tMvgDCYqHJIGjYG+IbQ/MhbicUEalyvOkbfyTwJFAX2Ak0BJbj3Hovy1ygmTGmMbAFp3/9Cw475nPg+cJhc0OBHsD/O5ZfQPxMRDxc8gWk7YS5r8Psl2HZZ84E4AmDkAhnUJ5ul0Obs9zNKyJSBXhzZf8Q0BP4wVrbyRgzEBh7tBdZa/OMMeOB7wAP8Ka1dqkx5urC/S9ba5cbY74FFgEFOLf9lxzvLyN+JLoWDLz778fy8nPgz7cgfTcsfA82/OpM0bWhYS+304qIVGreFPtca+0eY0yQMSbIWjvdGPOoNye31n4NfH3YtpcPW38ceNzrxBJYgjwQWd1Z7n+7Mx/2iDPS3st9YcIwuOqXQ/vmFxGRclVqpzrF7DfGRAO/AO8aY54B8nwbSyq1oCDnNv7pTznrn13rbh4RkUrOm2I/CsgAbgK+BdYCZ/gylFQRXS9z5juWwAPxznR/HLw2CJZNdTebiEgl4s1t/FrANmttFjDJGBMBJAJ7fJpMKj9j4MZFsOAdsAXOtl+fgC3z4cOLYdxX0KivuxlFRCoBb67sP8JpPHdQfuE2kRMX3xAG3QOD73Wm+/bDRVOcfRNPh/mTIC9Hfe6LiJwAb4p9sLU25+BK4XKo7yJJlWYMNB0MV/0KEdXhixvgvzXh6fawbobb6UREApI3xX5X4bP2ABhjRgG7fRdJBKjTHi7/Hgb/Bxr1g5RN8NYo+O4e5/G97FRd7YuIeMmbYn81cLcxZrMxZhNwB3CVb2OJAAlNod8tMO5LOPMlZ9sfz8PjTeD/kuDNYc4tfhERKdNRG+hZa9cCPQsfvzPW2lTfxxI5TMcLoN25TmO+nDTYvhgWfQDLp0KL4RAa5XZCERG/5U13uYnA/4C61trhxpjWQC9r7Rs+TydSnCcEul7qLGfshZXfwieXO+vdr4SI4e5lExHxY97cxp+I0+Vt3cL1VcC/fBVIxCuR1eGKH2Dgv531Oa/SfNXLZb9GRKSK8qbYJ1hrP6Tw8TtrbR7O43ci7qrZHPrfBvdsh+hE6m77Dua8BrlZbicTEfEr3hT7dGNMDcACGGN6Aik+TSVyLEIi4Pz3nOWvb3Ua8M18BrIOuJtLRMRPeFPsbwamAk2MMTOBt4DrfZpK5FgldWV29xehy6XgCYXv/wPPdIAD29xOJiLiOm9a4/9pjOkPtAAMsBLo7utgIscqM7IeDLjQGWBnyhWw5BN4qiU0PhmiakJcEgy4y7kTICJShZRa7I0xHuA8oB7wTeFY9COAV4EIoFPFRBQ5RkFBMOpFaHUGLP0UdiyF9b84+2Y+A23Ocj4QHBx6V0Skkivryv4NoD4wB3jOGLMR6AncZa39rCLCiRy3kHCnqLc5y1nPToNPr4KNM50PAJn74B+fu5tRRKSClFXsuwLtrbUFxphwnC5ym1prt1dMNJFyFBYN57/rLL860Oln/4t/QZdxEBHvDMgjIlJJldVAL8dae/BxuyxglQq9VAqXfg0N+8L8CfBqf3imPXx0KeTnuZ1MRMQnyrqyb2mMWVS4bHBa4y8qXLbW2vY+TyfiCyERcP47sGkWpCTD9P/B0imQsRtGPA01mridUESkXJVV7FtVWAqRihYR7/SpD87jeu+dC2t/gpXfQO/x7mYTESlnpRZ7a+3Gigwi4hpPMFw0BZ7vCtPugVXfln5s23P+7p9fRCRAHPU5e5EqwRgYeI/T3W5BKb1B714F0+6FRR8664mt4bQnnNeKiPgxFXuRg9qe7UylWfEVzHrJWd67Djb9Dht+g/C4Ul5g4MIPy9gvIlIxVOxFvNXydGcCKCiAmf/v7856DrdjKaTvgkcawGXfQYOeFZdTROQwZfWgt5jCwW9Kotb4UqUFBUG/W5ypJNY6/fP//ixMOgOu+QMSmlZsRhGRQmVd2Y8onF9XOH+7cH4hkOGzRCKVgTEw5CHYMt/ptW/iaTDyeWgyyGkQKCJSgUrtVMdau7GwRX4fa+3t1trFhdOdwNCKiygSwP7xOZzyAKTtcB7vezgRNv7udioRqWK8GeI2yhjT9+CKMaY3EOW7SCKViCcE+v4Lxs+HZkOgIA8mDIdPrqDG7tmlt/wXESlH3txPvBx40xhzsEnxfuAy30USqYQSmsKFH8GyqfDJFbD4I9oBJMVCz2vcTicilZw349nPBzoYY2IBY61N8X0skUqq9Uhotgn2rce+2Avz7Z3OI30dzodGfSG+kdsJRaQSOmqxN8aEAecAjYBgU9iBiLX2QZ8mE6msQsKhVisWdHqUznnzYM338Pl1TuO9iz91O52IVELefGf/OTAKyAPSi00icgIOxLWAc16Dm5ZCi9OcvvmXf+l2LBGphLz5zj7JWjvM50lEqqrQKDjndXjlZOcKP207GA+0HgWR1d1OJyKVgDdX9r8bY9r5PIlIVRYaBb2vh6wU+OoW+PJf8FhjOLDN7WQiUgl4U+z7AvONMSuNMYuMMYuLjXMvIuWlyzi4Yz3cuhpOGuhse3Mo/PECZO5zNZqIBDZvbuMP93kKEXFExDvzf3wGiz+G6Q/Dd3c704WfQLNT3M0nIgHpqFf2xXrSy8TpK//gJCK+1G40XP8n9L3ZWX/3HJg4An57GhZ95G42EQko3jx6NxJ4EqgL7AQaAsuBNr6NJiIYA6fc5/TCN+kM2PCrMwFMuQKCgp1e+a78Gep2dDeriPgtb27jPwT0BH6w1nYyxgwExvo2logcIjwO/jkD8rIgNxPmvAJ52bB5Dmz6Hd4f63znX9gPRsmMc7egeuMKCi0i/sKbYp9rrd1jjAkyxgRZa6cbYx71eTIROVRQEIRGOtPAu//evmoafHwZzPjf0c8x/b9ggqDPjXDK/b5KKiJ+xptiv98YEw38ArxrjNmJ08GOiPiD5kPgzk0ctSnN2umweTb88hj89v+g44WQ0KxCIoqIu7x59G4Uzvj1NwHfAmuBM3wZSkSOUVAQBHnKnpqdAoPugbNfc14z6QxI3e5ubhGpEN4MhHOwa9wCYJJv44iIz7U/D/Jz4fNr4ckW0Gv839/1h0ZD9yvVc59IJePNbV2KFR0AACAASURBVHwRqWw6XQj52TDtXpj3prPNWsjLhBn/B2c8A63PdLYHeSAsxr2sInLCVOxFqqqulzlTcTMedRr6fXGjMx3U81rod2vF5hORcqNiLyJ/G3AH9LsFlnwMGXudbau+gVkvwqwXiW//ADDAzYQichy86VSnD3A/Tmc6wYABrLX2JN9GExFXeIKhw/l/r/e61nm8771z6bDoPqgT6mwTkYDhTWv8N4CncAbE6QZ0LZyLSFXRfAiMeNpZ/uE+d7OIyDHz5jZ+irX2G58nERH/1vVSVq5aSYtVL8F7YyCyxqH7G/SCxv3AEwqxdd3JKCIl8qbYTzfGPA5MAbIPbrTW/umzVCLil7bXHkyL4G2wZf6hO1I2w8J3/14/dyK0OatCs4lI6bwp9j0K512LbbPAoKO90BgzDHgG8ACvW2sfKeW4bsAsYIy19mMvMomIC2xQCJxXQncbO1fA1sLP/1/eDJ9e43TY0/Oaig0oIiXyplOdgcdzYmOMB3gBOBVIBuYaY6Zaa5eVcNyjwHfH83NExA/UaulMALtWwuKP4ds7Yd3PcP57Tg9/IuKao/4LNMbEGWOeMsbMK5yeNMbEeXHu7sAaa+06a20OMBmn693DXQ98gjN8rogEulMfgBv/gtrtnMf2nusEH1zkPLev7nlFXOHNx+03gVTgvMLpADDBi9fVAzYXW08u3FbEGFMPOAt42ZuwIhIgPMFw+Q+Q1B1CImHHMpg/0emed85rUFDgdkKRKsVYW/ZIWcaYhdbajkfbVsLrzgWGWmuvKFy/GOhurb2+2DEfAU9aa2cZYyYCX5b0nb0x5krgSoDExMQukydPJi0tjejoaK9+SX8QaHkh8DIrr++dSOb6m6bQeP27BNk80qIasbDjf8kL8W03vIH2HgdaXgi8zIGad+DAgfOttV2P/opSWGvLnIA/gL7F1vsAf3jxul7Ad8XW7wLuOuyY9cCGwikN51b+mWWdt0uXLtZaa6dPn24DSaDltTbwMiuv751w5twsa398yNr7Yp1pytXW5uWUS7aSBNp7HGh5rQ28zIGaF5hnj1J3y5q8aY1/DTCp8Ht6A+wFxnnxurlAM2NMY2ALcD5wwWEfNBofXC52Zf+ZF+cWkUAUHAYD74HcTOd2/l/vwY4lUKcDnPGsGvKJ+MhR/2VZaxdaazsA7YF21tpO1tq/vHhdHjAep5X9cuBDa+1SY8zVxpirTzS4iAQoY2Dow3DPdqfw2wJY8DZMPA3+mux2OpFKqdQre2PMRdbad4wxNx+2HQBr7VNHO7m19mvg68O2ldgYz1o7zou8IlJZBAVB/9uh9w3w6VWw/AvY9AfMfQPGvA0xtd1OKFJplHUbP6pwroGsRcR3QsKdjnpSt8OE4ZA8B55qBfW6QkIzGPJfiKzudkqRgFZqsbfWvlI4f6Di4ohIlRVTG25Y4HTEM+dV2LPG6YJ34btQrwuc/RrUaOJ2SpGA5E2nOo8ZY2KNMSHGmB+NMbuNMRdVRDgRqYJO6g/nvwvXzYZ+t0K1hk5f/M91htXfu51OJCB50/R1iLX2ADACp2Oc5sBtPk0lIgIw+F6nN77hjzvr758PS6Y43+8v/wKS55f9ehEBvBsIJ6RwfhrwvrV278FGeiIiPmcM9LgSomvBR5fAx5ceuj+xHbQbDfGNnEf4qjcu8TQiVZk3xf4LY8wKIBO41hhTE8jybSwRkcO0HgXj50Fe4X8/GXtg3puw8hv44b6/j0to4cxbDIfgARUeU8QfeTPq3Z3GmEeBA9bafGNMOiUPaCMi4jvGOK3ziztpAGSnwf5NsHoabF3gbF/2GexeSfeIDyH4CoirD437Q0xiRacW8QtlPWc/yFr7kzHm7GLbih8yxZfBRES8EhYNia2d6aCsA7D4Q4J+eAR+fPDv7fGNnN77Bt0LQcX++wsOg1YjnQF8RCqhsv5m9wd+As4oYZ9FxV5E/FV4LHS7gtmpjenfoRHsXg3LPoe1P0LaDpg6vuTXdRnnPN8PEFENWo5w7iiIBLiynrO/r3B+aWnHiIj4MxvkcZ7Nr9EEWgxzNqYkQ35u8aNgduFz/fMnOtNB9Xs6vflF16rA1CLl76j3rIwx/wMes9buL1yPB26x1v7b1+FERMpdXNKR24Y/4szTdzu3+fOy4Y1TYPMseKIZtDsPGvT8+/h6XaBumaN8i/gVb76gGm6tvfvgirV2nzHmNEDFXkQql6iEv5dvXQN/PAc/3A+LP3Sm4i75Ehr3q9B4IsfLm2LvMcaEWWuzAYwxEUCYb2OJiLjMEwx9b4Ie10BWyt/bty+Gd8+BSSMgIt7ZZgucEfx6XOVOVpGj8KbYvwP8aIyZgNMw7zJgkk9TiYj4i5BwZzooJhHGfe083nfQnFfhm9uh1RkQW7fiM4ochTfP2T9mjFkEnAIY4CFr7Xc+TyYi4q8a9XGmgxr0hM+uhWc7wRU/QO127mUTV81at4cZK3dx06nNCAv2uB2niDd94wMsB7611t4C/GqM0bC3IiIHtT0HRk9wevfbscztNOKiPzft4+Wf12Kt20kO5c2od/8EPgZeKdxUD/is9FeIiFRBB1vrb/zN3Rziqr5NE/jPiNaEery9lq4Y3nxnfx3QHZgNYK1dbYzRQ6ciIsVFVnc64fnzLQiPg1MePHR/kH/95y++0T6pGu2Tqrkd4wjeFPtsa23Owa5yjTHBOA31RESkuOGPOQPz/P6cMxXX7jw45zV3ckmF2XEgi9SsPJrWinY7yiG8KfY/G2PuBiKMMacC1wJf+DaWiEgAiqsH92yDv96H1B3ONlsAPz/iPKc/6B6nf36ptF6asZZP/kxm8f1D3Y5yCG+K/R3AFcBi4Crga+B1X4YSEQlYwWFOH/vFdbwAnmkPz3SAm5Y5HwqkUsrNLyAs2P++simz2BtjgoBF1tq2gO4/iYgcj/iG0P8O+PlR+H+tocXp0GQgdP+n28mknOXkFRDiZ43z4CjF3lpbYIz5yxjTwFq7qaJCiYhUOgPvhhrNYMFbsPIrZ4qtBy1PczuZlKPc/AAs9oXqAEuNMXOA9IMbrbUjfZZKRKQyan+uM637Gd4aCV/fCk1PgeBQt5NJOcnNt4QG2m38Qg/4PIWISFVyUn+48GN4d7TTx36t1oClRnYSpLaE6EQofAJKAstFPRuSkpl79AMrWKnF3hgTDlwNNMVpnPeGtTavooKJiFRqTU+B7lfB0k9h73pI30k7gCX/dQbYueZ39bMfgHo1qeF2hBKVda9hEtAVp9APB56skEQiIlWBMXDaY3Dbame64idWNr8WQqMhcx+s0hAkgWjF9gOs3pHqdowjlFXsW1trL7LWvgKMBjRws4iIryR1YVvdoXDDQmc9L9vdPHJc7v1sCfdNXep2jCOUVeyLvnTQ7XsRkQpycDjdb++A1O3uZpFj5q+P3pWVqIMx5kDhlAq0P7hsjDlQUQFFRKqUsBhI6uYsP9kC3jkHti50N5N4LSffBlaxt9Z6rLWxhVOMtTa42HJsRYYUEalSLv8eznkD4hvDmh/gtUH43ZipUiJ/7UHP/xKJiFR1xkC70XDjQuh6Odh8mPWi26nEC85tfP97bFLFXkTEnw1/DEJj4Lu74c1hsPQzOLDN7VRSigdHtWFcn8ZuxziCN53qiIiIWzzBcPl38MeLsPAd2PSHs33sB9BsCATpms2fDGhRy+0IJdLfEhERf5fYBs58AW5eAQPugpBIeH+Mc7Wfl+N2Oinm19W7WLcrze0YR1CxFxEJFLF1YMCdcNNSqNMBZr8Ez3aCCafD+l8geR4UFLidskr751vzmDx3s9sxjqDb+CIigSayOlz1Cyx4Fz6/Fg4kw6TfnH2tz4TzJrmbrwrLzbd+2UBPxV5EJFB1uhDaj4Et8yAnzXkmf8t8t1NVWfkFlvwCS6jH43aUI+g2vohIIPMEQ4OezsA6Q/8HKZvhxd7Orf2969xOV6Xk5jtfoYQE68peRER8pds/oSAf1v4I62bAW2c6t/wPF98Ymp3qjK4XEQ/1e2hI3XKQU1jsQ/2wBz0VexGRyiI4FPrcAL2vh29uh30bjjzGFsCGX2HplL+3RSbA2PehfvcKi1oZRYR4ePvy7jSqEeV2lCOo2IuIVDbGwGmPl76/oAB2rYD8bFjxFfzyOLxxKox6EVoML/lugBxViCeIfs1quh2jRP53r0FERHwrKAgSW0PdTjDo33BuYev9z6+Fr29zN1sAS8vO48tFW9myP9PtKEdQsRcRqeranAk3LIQWp8GSj+HLmzTwznHYnpLF+PcWMG/DXrejHEG38UVEBKo3dlrzb5kP896EZVOd4Xbbng2D/+N2uoBwsDW+Rr0TERH/Vb0x/GsJDPw3NBkEmXvhjxcgP8/tZAEhJ6/w0Ts/bI3vf4lERMQ9waHQ/zY45zVnxL28LPhvTZj1Euxe7XY6v1b0nL2KvYiIBIzmQ+Gkgc7jet/eCc93hQ0z3U7lt4qes9dtfBERCRgR8fCPz+C2dXD592A88MnlkJftdjK/1LZeHFOu7U2burFuRzmCGuiJiEjZomo408C74Kf/wos9od25EJdERIbHabmvHviIDQ+hc4N4t2OUSMVeRES80+9WwMDyqfDzY4ClB8DC252rfoDoWtDtcuhxdZX7ALBpTwaz1u1haNvaxEWEuB3nED4t9saYYcAzgAd43Vr7yGH7LwTuKFxNA66x1v7ly0wiInKcjIGTb3WmnAw4sJWV016nRfGL2Y0zne/3v70TQop1G9v2LBj5fKX+ALBg8z5u/2QRXRvFV51ib4zxAC8ApwLJwFxjzFRr7bJih60H+ltr9xljhgOvgvNBUURE/FhoJCQ0ZVvdYbQYMODv7fm58NvTkLX/720pm2HBO7DoIwgKdgbh6fwPaDq4wmP7UrYfP3rnyyv77sAaa+06AGPMZGAUUFTsrbW/Fzt+FpDkwzwiIuJrnhDn0b3iCvJh7utwYIvTmn/ZZ84UHA5j3nGK/3HIys1n7a402tSNK4fgJ276ip2Af3aqY6yPukQ0xowGhllrryhcvxjoYa0dX8rxtwItDx5/2L4rgSsBEhMTu0yePJm0tDSio6N9kt0XAi0vBF5m5fW9QMusvL53PJmjU9dRa+evNNg8hTxPFJvrj2RbnVPJCavh1et/2pRLcloBP21yOvu5q3s4Lap7fJbXWw/PymT1/gJeHxJJcFD5fF1xMO/AgQPnW2u7Hu95fHllX9JvWuInC2PMQOByoG9J+621r+Lc4qdr1652wIABzJgxgwHFbx35uUDLC4GXWXl9L9AyK6/vHV/mAcBlsP5SgidfSOMN79M4fz007sfqoCYM/TaaGjERvH15dxpWj2LDnnSS4iOICQ/hQFYu476dBkDvJjX4fe0e9oTXZcCAVj7M651J6+fQvUUEpwxqV27nLK+8viz2yUD9YutJwNbDDzLGtAdeB4Zba/f4MI+IiPiTxifDXZthxiPw86OweRbNgHXhMC79NmLC+9DqP98WHf7r7QO56u35ALSpG8tbl3Wn/+MzePWXdQxtk0iXhu4OzTvh0u6u/vyy+PKLhblAM2NMY2NMKHA+MLX4AcaYBsAU4GJr7SofZhERKTcHv/601rJ6Rypv/LaebxZvczlVABtwJ9y3j8/7f80reSMAmBj6OPXMHmLC/r4mvfvTxSzbdoD7z2jNVzf0I9gTRMMakQCc89IfNLrzK1Iycl35Ffydz67srbV5xpjxwHc4j969aa1daoy5unD/y8B/gBrAi8Z5HCPvRL6TEBEpL7+v2U3DhCiqRYTgCTKs3J7KSTWjiAoN5r6pS1mweR9703LYmpIFwBkd6jK8XR1y8gqKukvNyy9gR2o29apFHHLunalZ/LlxPy1qx9A44e/H0wqsZev+TKpFhhAZWvW6QRk1sA/LW7aDhfVh9kswcQSLxz6MbXEaAL+u3s3Y7g04rV2dote89o+utH9gGvkFzgewt2dtoHliDKe2TsRU4GN+m/ZkcPOHC7l9WEu6N3b3DkNJfPq3yVr7NfD1YdteLrZ8BXBEgzwREV/LyStgwaZ9LN6Swiu/rCMhOoxTW9Xi5iEtsNbyyLcrWJSccshr3r68O32bJhAaHERevqVTw3iub5pAm7qx1I4LJz07jzb3fUfzxGhCg4NYsuUAACseGkZ4iIfBT85g7a70ovOFhwQx49aB1I4Lp9GdXzkbv/sJgMdHt+fcrvUpb5k5+eTkFRAV5uHnVbv4KzmFpGoRnN25Hsu3pTJj5U4Gt0okqXoE3y7eTrPEaDo1iOdAVi45eQUkRIcd889MycwlyEBMeAhp2XlEhniYvX4vY1+bRXhIEFm5BZxUM4ofb+5PqzqxUOcRqN0WPr8OJl+AOe9taD2Sk5vXPOLcUWHBrHl4OBk5+fy5aR8XvzEHgOsHNeWWIS1O+P3y1r6MHOZt3Edqln/eWah6Hx1FpFxZa4uuoP7avJ896dnUqxZJWnYe4SFBRY9FLdmSwq7UbOZv3Efz2jFUiwihT9MEPEGGtOw8Vu9IpVZsODWiQgkP+btl9ea9GWTm5hMe7CEpPgJjIK/AEuIJYltKJjPX7CEy1EN6dh570nOwFq7ufxLGGFbuzSdn6XZ2pmYTFeZhwab9VI8K5cbBzVi+7QBjXp1V9HPqxIUzZcEWBrdKpE3dWE5vV4e6cc7Pa1ormha1Y2hbNw5jDPeOaF3ie7F2Vxr1qkWQnVdARIiHMzvWpXPDeKx1RkTLyi2gVZ1YmtSM4pRWiexKzaZ2XDgAIzvUZe/unUTG1WDash0s3Lyfszsn0eTur6kbF8702wYQFuwhv8DiOYaW3lv2Z/Lj8h00qhHFyc1rsmZnGmc8/xuRoR4ycvKLjuvVpAZ3fbqIJVsO8OT3zreqLWvH8N4/ezJ3w17OffmPomM/vroX7ZOqERocxL6sAtbvTmfLvkzW70nnQGYuHetXo0/TBDJz8nn6h1W8M2sj6Tn5NKkZRV6B5asb+rEz1bkjkpVbUHTeAgueg79ap4ugUT94ayRMuRJanVFqhzzGGIyhqNDPuXswtWLDvX6PykNmrvNeRoR691RARVOxF6nEUjJyWbI1hW0pWWTm5HFW5ySiQj288ss69qRlkxgbTogniH0ZOYxoX4emtWL4bfVufluzm5TMXPalO1crdeLC+fCqXgCMemEmDatHsmV/Jsn7MoiPDOXbf50MwEVvzCY169Cxz9c8PJxgTxDP/bSa75buOGTf9zedTMMaUVz42iz+KnYVXTs2nPtHtmZY2zr896tlh7wuOiyYu05ryYU9GrJqRxq3fnRkp5uX9W1EWLCHP7bl8X9z5h+yr2XtGG4Y1IwWtWN4ekxHujaKp161iCNu+V7Vv8kxv99NakYz885Bpe4va9+zYzsVtrzuyg/LdhR9F92tUTxzN+yjxb+dhmonJUTx060DyM7L58N5yTSsHklmbj4rtqUyc81unji3A7vSsjjnpT+IiwghJdO50hzbvQEnN69Jk1pR3DGsJcn7MujXLIG+zWoydeFW6sSF86/BzXln9kaS4iOoExdBh6RqxEeG0DghivO6JvHhvGQARr/8B7PuGkztuHA+XJXDTTNmHPK7DGmdSKcG1QgL9vD+nE2kF36oaJwQzentaxMV6mFkh7p0bVSdfek5tKkbS05+wZEfYuIbQtfL4ft74aeHYPB/Sn3/dh5wBucJ8Rjmb9zH/75Zzhfj+1ItMrTU13hj3oa9zN+4j8v7Nia4jM5yiop9iIq9iPhAWnYee9Ky2bI/k84N4gkP8fDB3E089u1K9qTnHHLsed3q89ua3TzyzYojztO0VjRNa8WwLSWTN39bT2xECNUiQ2hdOIJXeEgQq/bl89fmdP7avJ9eJ9WgX7OaNKn59zPLr1zchaVbDhAUZNhxIIudB7KK/gM/s2M9mtWKoedJNfgreT9NakZRt5pz5XxWp3pc0rsRczfsIzwkiO0pWYQFO/9p3nRqc9rWjSM1O48fl++ga8PqRT+zR+PqfDG+L8Y4V84F1tI8MabotaOahHDjGd2pHhVKSmYuSfGRxIYHExRkCA/ycGaneuX/B1IOTmmdWLT80dW9mTBzPWt2prEzNZtWtWMAeOCLZbw3e9Mhr7ttaAsa1Ihkf6bz555fYLltaAtOb1en6MNDZGgw1ww49IPMBT0aFP3c4j/7oIToMB4b3YH7R7Zh/sZ9pGXlUS3S6Q52YP0QRvdpS734COpXjyQmPJjvl+4oanOw8D9DCCrlTkS9ahFF7RkO/pkdodd4+PUJ+P35Mot9o4Qo5v/7FKpHhfLcT2vYvDeT/3y+lGfHdir1NUezMzWL0YV3NNonVaNXkxpYa8nMzT+iTUVWjq7sRSq9lIxcNu5NJ3lfJut2pXFet/rUjA7j3dmb+GOd80Tpul3pdG0YT5u6sZzfvQHWWu6aspjYiGCWbElhy75MXrywC63rxpKbX8A7szZSMyaMiBAP2XkFNKwRSdNa0YQFe5i7YS9PfLeS9bvT2Zn693Cjn1zTmy4N46kTF8GprRM5qWYUDapH0qRmNIlx4QQZQ79mNVn/f6exNz2HDXsyaFgjkmoRIUVXLed0Tir1u+KT4oJ4+aIutEuKO6LRGUDvJgn0bpJQ4muHt6vD8MKGVX2bHXrMuD6NATi785GdaLasHUvL2s4HjrtPO/RZ6vAQD+2SSu89LT48iE5+OgrZsbi08P0p7n9nteOGQc1YujWFDXsyGNyyFo0KG/u1T6rGn/eeSnxkSLk2UosMDaZfs0O/N28e72FAl0P/3M4ptl5aofdaUBA0GwKLP4KvboXTnyj10BqF7Qn6NK3BU9/D1L+2cvuwFiTFRx7Xjw4L9hTd0dh+IBOAh79azuu/rWfZg0OJDA0mKzef1TvSiAwLpl29OGLC/atP/INU7EWOIievgKVbU9ifkUtOfgG7UrPpkFSNdklxLNmSwj2fLmbxlhQKinUZ1bZeHP2b1+T3tbuZsXIXGTn5RIV6WL7tAFeefBIAa/YX8P6cTQQZil572rO/suGR08kvsDzwxbIjsjxzfkdGdaxHcJAhr8BycvOaNE6IonZsOLViw2hReNV3cvOaJTZmOsgYQ43osKL/HIsr6z/n4CDDKW1re/O2SQWoHRde9J3/4apHndjta79y2uNOsZ/7GrQYBk1PKfPwLg2rM+Xa3jzwxTJ2pWaz40A2n/yZzEOj2h7Tj42LCOH+kW34bMFWXv91PT1PqsHrv60HYOHm/XRIqsa/P1vCpwu2sOzBoXxxfYn9wvkFFXuRwxQUWFIyc4mPCmV3WjZ9H/3pkEZEADed0px2SXFUjwolItTDtQOa0j4pjqT4SJKqRxBb+On+xQu7AM4t5hBPENl5+aRnO7f7mlQLYvH9QwgP8eAxhkVbUvh11S7AaYD2yTW9iQ4LJiUzlz1p2eQVWOpXd65QOjWI55NrelfUWyLiroh4uHY2vNgDFr4P1U+C+MZljqDXuUE8n1/XB4DXflnHe7M3USc2nHbHcJd9b3oOu9OyeWx0e2av30P1qFBuPrU5T32/igtem33Isf7+qKR/pxM5Dhk5eaRk5hLiCSIhOgxrLb+v3cOK7ank5RewcW8G63alcdXJTRjYshZfL97GXVMWExMeTHxkKJv2ZhAXEcIvtw8kITqM/53VjoycfJrUjMZiaVTDuZIGqFstgslX9jpqpoOjYIUFe4q+mwwy5pBbfh3rV6Nj/WqA0witS8PAv/0sUm5qtYS6nWHJx8409P+g17VevfSfJ5/E72t389QPq2gUG0St5geK2qKUJje/gEvenMOSrSl8c2O/ovYd4wc25anCpxVqxYRx74jWDG3j/3e7VOzFrxV/rGvF9gOs2pHG1v2ZTFu6HU+Q4cFRbWlVJ5Yfl+/gnl8z2P7tV0WvjQkLZtH9QwC48PXZR5z7jA51i5ZrxYQRHuIhIsTDqa0T6dIwnrz8AoI9QSV+jywiLjj7Ndi6AKZcAd/dBV3GOUPteuHxczvw9h8befXn1bz6y1qePr/shntPTFvJ4i0pPD2mY1GbEXC+5vr6hn5s2pvOyc1r+v0V/UGBkVIqrZ2pWaRk5NIsMYavFm3j3dkbWbcrne0HnGdwmydGM+2m/mTm5HPphLlsK+ytLC4ihKzcfBZu3k+rOrHkFVi2p1va1ould5MEDNCkVnTRB4X3ruhBWEgQTWvGEBMeTF6BJSvPuZ1+Wrs6h/TIJSJ+KqGpM639Cf56D768CUY+C8FH7+gnIfr/t3ffUVLVdx/H39/dZVnq0jtIly6KVLFgLIBGJJKIxJqoMdGo8WjgaDT65DHRmHM0Rg2xPcboCXaDghor9oJSVRAQEKQjbSm77O73+ePexXEdYBYY7p3Zz+ucPXPntvns5bLfue33q8lvTuzKjrVfcVz/dryzcB1rtxTTs1V98nJzdrVkuHzDNiZOW8Qj73/FuIHtkj6x0aNV/b2eGYgbFXs5qMrLndVbdlBa5hSXljPyr2/xxx/1pkvzemzfWca2kjLaNapNx6Z1aN+kDnk5hnvQiMjdPz2C+gV5NKpTk4bhYz8VPTSf3LMFDw2vw3HHHZ30c4d0/u7d3/k5tqtJUxHJMKPugs+fg9mTYNMyuGDq3pcJDW6Vx+BOjbnq8Zk8/cnXu8b3al2fe885knVFJbsK/U2n9UxH+kio2EtalJc7yzZsY8n6bazZvIOjOjehVYNaPD3j6+81grI6PIof068NY/olP2Wen2cckeQRqoPY9LWIxEVOLlz6AfzzVFj6Dmz7BmpXrT368cO78eXarTSpm8+gjo15a8E6mtcvoFm9mnx608nUqZld5TG7fhs5qLYWl/Lpis288vlqnpi+jBk3nMTOsnLG3vs+X64tYkNC71O3/Kg3Ywe0o3/7hvzulO7UzMvBzGharyY/6NYswt9CRDJSYWsYehVMvgy2b6hysW9ev4Bnw7v1AS48umM4ZHtsKS9Tfi6LgwAAEuNJREFUqdhLSraVlFLuwV3iM5dt5OonZrFobdGu0+gAO8LT8Pm5ObvaFz+0RT2a1K1J57DFs0Ma10n4TyUish8ahX9LvngRBl8abZaYU7GXpJZv2MYLi3dy+6fvsHrTDlZt3sFNp/XkvCHtaVI3n/aNa3Nqn5b0aVNIr9aF1MnPo6BGLgU1cvn3xYOiji8i1UH7oyAnD+Y+BYN+pet6e6BiL7vuat+wtYQRvVvi7vxk4nus2FQClHBC92ac2b/true+2zSszf3n9Y82tIgIQNtBsPRtWPpuUPwlKRX7amraF2t5+pPlzFu5hfmrtwBQvyCP4b1aYGbcckYfls6fw7hThlWpO00RkYPqhBvhgRPg/XtU7PdAxT7Lbdmxk+dnr2Tz9p386YV5/HxoB64/tQdfrd/Ke4vW06t1Icd3b0arwgJO7tli13Ppx3RtyhsrclToRSTe2vaHGnVg3vOw4GXocmLUiWJJxT6LrC8qZsGaIgZ1bAzAT/7xHh8u/mbX9K7N63Lu4EMAGDugHWcPOuSA9oglIhKJ85+D+46HR8fAjZuiThNLKvYZbF1RMe8tWs+sZRuZu2ITM77aSM28HGb9/iTMjCGdGjO0cxNKy53Rh7fe1UIUfNtWu4hIxmvdD3qMgs/+A5tXQn21iFmZin2GKSt3tuzYSf2CGjz83lLufHUB+Xk5dG9Zn7MGtOO0vq1wD25KvfKErlHHFRE5OA49JSj2xZsBFfvKVOwzxMZtJVz7zBymzlkFwLRrjuPH/dpwfLdm9ArbdhYRqbYqOsQpLY42R0yp2MfczrJyRt/zDgvXFLFjZzl5OUbftg3IMaNto9q7+jcXEanWcsPOcMpKos0RUyr2MVFW7kyZs5J/vruErcWl7Cwr56ELBtCwTj6lZc6IXi258OgO9GxVGHVUEZH4ycsPXnVkn5SKfYSKS8uomZfLio3bGX7Hm2zeUQpAfm4Ogzo1pkVhATVyc3jxymMiTioiEnO7juxV7JNRsT/I1mzewRMfL+fJj5ezeN1W3h4/jNYNajGqb2sKa9Vg3MB2tCws0CNxIiJVUXFk/6/RcOVcaNA22jwxo2J/kHxdVE77CVN2vW9StyZHd2lC6wa1MDP+cHqvCNOJiGS45r2hRR9YNRv+2gf6jIXRf486VWyo2KeJu/PWgnVs2VHKKX1aUlwadA83+vDW/PK4TnRtXi/ihCIiWSQvH37xJqxfBPcfH7Soh4p9BRX7A8zdeeT9pfz5xflsKS7lsLYNGNm7BR0b5LL4TyN1el5EJF3MoElnGPhLmHYrlJdDjh5LBhX7A2rhmiJOvH0a7sFNdv8zqidn9m+7q8Cr0IuIHAQFhYAHDezUahB1mlhQsd9PS9dvZfmG7RzVuQn5uTm4w3Uju3Ph0R1U3EVEolAQPqK85jM4ZEi0WWJCxX4fLV63ldtf/oLJs1ZQWKsGM284kXaNa+tUvYhI1NoNCl6nXA19z4K+P4XajaLNFDFdzKiipeu3cu6DHzLsL28wedYKercu5NELB+6arkIvIhKxxp1g5F9gw2L47+/g7gEw/UFwjzpZZHRkn6Il67bSorCAmnm5vPnFWs4f0p5Lh3Wmab2aUUcTEZHKBlwER/4cVs+BF6+F538DX39CQf5RUSeLhIr9XqzctJ1bX5jH0m+28fDPBtCisICFN49QxzMiInGXkwMtD4Pzn4cXxsOH/2AQ/4KGm6Df+ZBXM7iDvxpQxdqN8nJn4rRFDP7Ta0ydu4rTDmtF3ZrBdyMVehGRDGIGI/8Ml89kY2EPeHE83NwcnvkFFBcFj+hlOR3ZJ7Flx05+9egnvLVgHR2b1uGh8wfQrrF6lxMRyWiNOjCv2xUMqrcSPpsMsx8LfvJqQZMu0LQb1GkafDmwHBhwcdY0u6tin0Sd/Dxq5OZw8+hejBvQTjfdiYhkiR21WsDQsXDUlfDZs7BhKWxdC2vnwdJ3YcfGYMaSrcH40ROjDXyAqNiHdpaVc/vLX3D+kPY0q1/AA+cdqSIvIpKtzKDn6N1Pn3oNfHgfHH110CpfhtPFZ2DtlmK6XPcC97yxiFc+XwPoEToRkWpt4CWAw1394JEzYOf2qBPtl2pf7HfsLGP4HW8CcMmxnRg3sF3EiUREJHKNO8GYB4Phha/Ae3dB2c5oM+2Hal3sy8udKybN4JttJdw17nAmjOgWdSQREYmLXmfA9eugZV947X/hjt7wzl9h+8aok1VZtS72m7bvZFtJGTf+sCen9mkVdRwREYmb3Bpw0esw7vHgbv2Xb4Dbe8Hqz6JOViXVutg3rJPPnWMP57wh7aOOIiIicZWTA11PhnOfhbOfgpItcO9xsGpu1MlSVq2LPQQFX0REJCWdTwhu3isrholHwbwpsGVV1Kn2So/eiYiIVMWIW4Nn8Oc+BZPGBeO6nAQN28PwWyAnN9J4yVT7I3sREZEqG/MgXL0ARtwGzXsH1/A/vBfWzo86WVIq9iIiIvuibjMYeDH88m0Y+2gwbv3CaDPthoq9iIjI/ipsE7xuWRltjt1QsRcREdlftRpBTg3YvCLqJEmp2IuIiOyvnByo17J6Htmb2XAzm29mC81sQpLpZmZ3htNnm9kR6cwjIiKSNvVawMZlUadIKm3F3sxygbuBEUAP4Cwz61FpthFAl/DnYuDv6cojIiKSVh2Pha/ehS+nRZ3ke9J5ZD8AWOjuX7p7CTAJGFVpnlHAwx54H2hgZi3TmElERCQ9hl4FjTrCc5dDybao03yHuXt6Vmw2Bhju7heG788BBrr7ZQnzPA/c4u5vh+9fBca7+/RK67qY4Mif5s2b95s0aRJFRUXUrVs3LdnTIdPyQuZlVt70y7TMypt+mZY53XkbbJjDIUsf5/Puv6GkZqP9Xl9F3mHDhn3s7kfu84rcPS0/wI+B+xPenwP8rdI8U4ChCe9fBfrtab39+vVzd/fXX3/dM0mm5XXPvMzKm36Zlll50y/TMh+UvOXlB2xVFXmB6b4fNTmdp/GXA20T3rcBKj+TkMo8IiIimcMs6gTfk85i/xHQxcw6mFk+MBaYXGmeycC54V35g4BN7h7P5xZEREQyVNo6wnH3UjO7DHgJyAUedPdPzeyScPpEYCowElgIbAMuSFceERGR6iqtvd65+1SCgp44bmLCsAOXpjODiIhIdacW9ERERLKcir2IiEiWU7EXERHJcir2IiIiWU7FXkREJMup2IuIiGQ5FXsREZEsp2IvIiKS5VTsRUREslzaurhNFzNbCywFmgDrIo5TFZmWFzIvs/KmX6ZlVt70y7TMmZr3EHdvuq8rybhiX8HMpvv+9O17kGVaXsi8zMqbfpmWWXnTL9MyV9e8Oo0vIiKS5VTsRUREslwmF/t7ow5QRZmWFzIvs/KmX6ZlVt70y7TM1TJvxl6zFxERkdRk8pG9iIiIpCDWxd7MGpnZy2a2IHxtuJv5hpvZfDNbaGYTkky/2szczJqkKefePt/M7M5w+mwzOyJhWgMze9LM5pnZ52Y2OB0Zq5i3m5m9Z2bFZnZ1pWlxzPvTcLvONrN3zeywKPOmmHlUmHemmU03s6FRZt5b3oT5+ptZmZmNiXNeMzvOzDaF23emmd0QZd5UMifknmlmn5rZtCgzp7CNr0nYvnPD/aJRjPMWmtlzZjYr3L4XJEyL5T5hZg3N7Jnwb8WHZtZrnzO7e2x/gD8DE8LhCcCtSebJBRYBHYF8YBbQI2F6W+Alwmfz05Bxj58fzjMSeAEwYBDwQcK0fwIXhsP5QIM0b9NU8jYD+gM3A1dXmhbHvEOAhuHwiCi3bxUy1+Xby2h9gHlx3sYJ870GTAXGxDkvcBzw/G6Wj+s+0QD4DGgXvm8W521caf4fAq/FOS9wLWENAZoC3wD5Md8nbgN+Hw53A17d120c6yN7YBTBL0T4enqSeQYAC939S3cvASaFy1W4HfgtkK6bE/b2+YTvH/bA+0ADM2tpZvWBY4AHANy9xN03pilnynndfY27fwTsTBwf47zvuvuG8O37QJsI86aaucjD/6VAHcL9M67bOPRr4ClgTcWImOf9njjvE8A44Gl3/yrMtibCzFXdxmcB/455XgfqmZkRfNn+BiiN+T7RA3g1zDUPaG9mzfclc9yLfXN3XwkQvjZLMk9rYFnC++XhOMzsNOBrd5+Vxoy7/fwU5ukIrAX+z8xmmNn9ZlYnjVn3lCUVmZD35wRnUSCavJBiZjMbbWbzgCnAz8LRsdzGZtYaGA1MrLRsLPOGBoenbF8ws54R5oXUMncFGprZG2b2sZmdG46P8zbGzGoDwwm+CEJ8894FdAdWAHOAK9y9PKK8qWaeBfwIwMwGAIcQHMxUOXPkxd7MXgmv91T+SembOsGp8co83AGvA25IMv1ASvr5Kc6TBxwB/N3dDwe2ElyuSKdU8u5OrPOa2TCCYj8+HBVFXkgxs7s/4+7dCM5Y/SEcHddtfAcw3t3LKo2Pa95PCJoXPQz4G/BsOD7O+0Qe0A84BTgZuN7MuhLfbVzhh8A77v5N+D6ueU8GZgKtgL7AXeERcpz3iVsIvgDOJDizNgMoZR8yR17s3f0Ed++V5Oc/wGozawkQvq5JsorlBNflK7Qh+ObWCegAzDKzJeH4T8ysxQH+FXb3+anMsxxY7u4fhOOfJPgHTKdU8u5p2VjmNbM+wP3AKHdfn7Dswc5b8bkpb2N3fxPoZMENpHHdxkcCk8L/S2OAe8zsdGKa1903u3tRODwVqBHh9oXU/0686O5b3X0d8CZwGDHdxgnGEp7CT1g2jnkvILhM4u6+EFhMcB08tvtEuB9f4O59gXMJ7jVYzD5kjrzY78Vk4Lxw+DzgP0nm+QjoYmYdzCyfYMeb7O5z3L2Zu7d39/YEG+cId191gDMm/fwkv8e5FhgEbHL3lWGWZWZ2aDjfDwhu0EmnVPImFde8ZtYOeBo4x92/iDhvqpk7h9cOseDpjHxgfVy3sbt3SPi/9CTwK3d/Nq55zaxFwvYdQPC3Lqrtm1Jmgr9vR5tZXnhmciDweVy3MQR3uAPHkvC3OcZ5vwqzYGbNgUOBL+O8T1hwx31++PZC4M3wC0DVM3ua7zjcnx+gMcHNCQvC10bh+FbA1IT5RgJfENzZeN1u1rWENNyNv7vPBy4BLgmHDbg7nD4HODJh2b7AdGA2wanGhgdhu+4tbwuCL0ebgY3hcP0Y570f2EBwim4mMD3K7Zti5vHAp2He94Chcd4nKs37EN+9Gz92eYHLwu07i+CmzSFx3yfC99cQ/NGeC1wZ520cvj8fmJRk2djlJagb/yX4GzwXODvu+wQwmKD+zSM4oGm4r5nVgp6IiEiWi/tpfBEREdlPKvYiIiJZTsVeREQky6nYi4iIZDkVexERkSynYi8SE2bW2L7tRWyVmX0dDm80swP+3K+Z3WiVejVMYZmi3Yx/yBJ6wtuPTAdkPSLyXSr2IjHh7uvdva8HrWVNBG4Ph/sC5Xtb3szy0p1RRDKTir1IZsg1s/ss6If7v2ZWCyDsNOWPFvR9foWZ9TOzaWFHKi8lNDd9uZl9ZkG/2JMS1tsjXMeXZnZ5xUgzuyqhn4orK4cJW4O8K1znFJJ0UmVm3c3sw4T37c1sdjh8g5l9FK7/3orW7iotvyRs4hYzO9LM3giH65jZg+HyMyz1fjREqi0Ve5HM0AW42917ErRqeEbCtAbufixwJ0GnL2PcvR/wIHBzOM8E4HB370PQQleFbgQdhAwAfm9mNcysH0E74gOBQcBFZnZ4pTyjCZob7Q1cBAypHNjdPwfyzaxjOOpM4PFw+C537+/uvYBawKlV2BbXEfSd3h8YBtxmB6eXMpGMpWIvkhkWu/vMcPhjoH3CtMfC10OBXsDLFvSS9TuCzjUgaFLzUTM7m6DXrApT3L3Yg45X1gDNgaHAMx50yFJE0Ezn0ZXyHAP8293L3H0F8Npucj8O/CQcPjMh6zAz+8DM5gDHAz2TLbwbJwETwt/xDaAAaFeF5UWqHV3jE8kMxQnDZQRHwxW2hq8GfOrug5MsfwpBgT6NoOvUiuJaeb15JO96M5lU2tp+DHjCzJ4G3N0XmFkBcA9BHxHLzOxGgoJdWSnfHpAkTjfgDHefn2JOkWpPR/Yi2WM+0NTMBgOEp+R7mlkO0NbdXwd+CzQA6u5hPW8Cp5tZ7fD0+GjgrSTzjDWz3PC+gGHJVuTuiwi+RFzPt0f1FYV7nZnVJegyN5klBP27w3cvW7wE/DqhV7vKlxhEpBId2YtkCXcvCR9buzPsejQPuIOgV61HwnFGcJf/xiT3xFWs5xMzewiouLnufnefUWm2ZwhOv88J1z9tD9EeA24DOoTr32hm94XLLiHo6jOZm4AHzOxa4IOE8X8If6/ZYcFfQtWu+YtUO+r1TkREJMvpNL6IiEiWU7EXERHJcir2IiIiWU7FXkREJMup2IuIiGQ5FXsREZEsp2IvIiKS5VTsRUREstz/A2ZIEm+uUnUFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "    \n",
    "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "    \n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "precision_recall_curve_plot(y_test, lgbm_clf_bayes_best.predict_proba(X_test)[:, 1] ) ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.341, 0.2505)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Find_threshold(model, X_test, y_test):\n",
    "    thresholds = np.arange(0,1,0.001)\n",
    "    threshold_count = []\n",
    "    pred_proba=model.predict_proba(X_test)\n",
    "    pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "    for threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=threshold)\n",
    "        model_cl_pred = binarizer.transform(pred_proba_1)\n",
    "        threshold_count.append([threshold, metrics.f1_score(model_cl_pred, y_test)])\n",
    "\n",
    "    MAX=thresholds[np.array(threshold_count)[:,1].argmax()]\n",
    "    \n",
    "    thresholds = np.arange(MAX-0.05,MAX+0.05,0.005)\n",
    "    threshold_count = []\n",
    "    for threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=threshold)\n",
    "        model_cl_pred = binarizer.transform(pred_proba_1)\n",
    "        #threshold_count.append([threshold, metrics.f1_score(log_cl_pred, y_test)])\n",
    "        #print('threshold: {0:.4f}, f1_score: {1:.4f}'.format(threshold,metrics.f1_score(model_cl_pred, y_test)))\n",
    "        threshold_count.append([threshold, metrics.f1_score(model_cl_pred, y_test)])\n",
    "    \n",
    "    return np.round(thresholds[np.array(threshold_count)[:,1].argmax()],4), np.round(metrics.f1_score(Binarizer(threshold=thresholds[np.array(threshold_count)[:,1].argmax()]).transform(pred_proba_1), y_test),4)\n",
    "\n",
    "Find_threshold(lgbm_clf_bayes_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[13088  1514]\n",
      " [  299   303]]\n",
      "정확도: 0.8808, 정밀도: 0.1668, 재현율: 0.5033, F1_score:  0.503322, ROC_AUC_Score:  0.250517\n"
     ]
    }
   ],
   "source": [
    "# Binarizer의 베스트 threshold 설정값 지정 \n",
    "\n",
    "custom_threshold = 0.341\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test , custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
